{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# San Francisco Crime Project\n",
    "\n",
    "* Author: Kevin Chuang [@k-chuang](https://www.github.com/k-chuang)\n",
    "* Created on: August 25, 2018\n",
    "* Description: Data analysis, exploration, visualization, and data mining on crime in SF\n",
    "* Original dataset: [SF Gov Crime dataset](https://data.sfgov.org/Public-Safety/-Change-Notice-Police-Department-Incidents/tmnf-yvry/about)\n",
    "* Kaggle dataset: [Kaggle SF Crime](https://www.kaggle.com/c/sf-crime/data)\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "- Introduction\n",
    "    - SF Crime Dataset\n",
    "- Basic Preparation\n",
    "    - Import libraries\n",
    "    - Load data\n",
    "- Data Exploration/Analysis Extension\n",
    "- Data Preprocessing\n",
    "    - Data Imputation/Removal\n",
    "    - Feature Engineering\n",
    "    - Feature Encoding\n",
    "- Build Machine Learning Models\n",
    "    - Train different baseline models\n",
    "    - Analyze results\n",
    "- Model Selection\n",
    "- Hyperparameter tuning\n",
    "- Train Model with optimal hyperparameters\n",
    "- Feature Selection\n",
    "    - Feature Importance\n",
    "    - Feature Removal\n",
    "- Train Final Model\n",
    "- Model Evaluation\n",
    "- Summary\n",
    "- Kaggle Submission\n",
    "- Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "## SF Crime Dataset\n",
    "\n",
    "This dataset contains incidents derived from SFPD Crime Incident Reporting system. The data ranges from 1/1/2003 to 5/13/2015. The training set and test set rotate every week, meaning week 1,3,5,7... belong to test set, week 2,4,6,8 belong to training set. The goal is to try to predict the category of crime that occurred in the city of San Francisco. \n",
    "\n",
    "### Data Fields\n",
    "- **Dates** - timestamp of the crime incident\n",
    "- **Category** - category of the crime incident (only in train.csv). This is the target variable you are going to predict.\n",
    "- **Descript** - detailed description of the crime incident (only in train.csv)\n",
    "- **DayOfWeek** - the day of the week\n",
    "- **PdDistrict** - name of the Police Department District\n",
    "- **Resolution** - how the crime incident was resolved (only in train.csv)\n",
    "- **Address** - the approximate street address of the crime incident \n",
    "- **X** - Longitude\n",
    "- **Y** - Latitude\n",
    "\n",
    "\n",
    "In this juypter notebook, I will go through the whole process, end-to-end, of creating a machine learning model on the open source San Francisco Crime dataset. This includes data exploration & analysis, data preprocessing (huge part of this project and includes feature engineering), trying out different ML algorithms and determining the optimal ML model, tuning the hyperparameters of that model, and finally, evaluating the chosen model in terms of multiclass log loss. \n",
    "\n",
    "Since this is an old Kaggle competition, I will refrain from looking online for resources or old Kaggle kernels. The plan is to get better at coding an end to end data science project and to familiarize myself with the Python data science libraries. Also, I hope to learn some interesting things and discover some cool patterns or ideas using this dataset. Well, here goes nothing!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:19.277666Z",
     "start_time": "2018-09-15T00:10:17.704742Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/me/.conda/envs/py39/lib/python3.9/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'Kevin Chuang (https://www.github.com/k-chuang)' \n",
    "\n",
    "# linear algebra\n",
    "import numpy as np \n",
    "\n",
    "# data processing\n",
    "import pandas as pd \n",
    "\n",
    "# data visualization\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "# Algorithms\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "\n",
    "# Metrics \n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Model Selection & Hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space  import Real, Categorical, Integer\n",
    "\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Mathematical Functions\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:22.111001Z",
     "start_time": "2018-09-15T00:10:19.280864Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:22.435882Z",
     "start_time": "2018-09-15T00:10:22.113556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 878049 entries, 0 to 878048\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   Dates       878049 non-null  object \n",
      " 1   Category    878049 non-null  object \n",
      " 2   Descript    878049 non-null  object \n",
      " 3   DayOfWeek   878049 non-null  object \n",
      " 4   PdDistrict  878049 non-null  object \n",
      " 5   Resolution  878049 non-null  object \n",
      " 6   Address     878049 non-null  object \n",
      " 7   X           878049 non-null  float64\n",
      " 8   Y           878049 non-null  float64\n",
      "dtypes: float64(2), object(7)\n",
      "memory usage: 60.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration & Analysis Extension\n",
    "\n",
    "- Complete data exploration & visualizations are located in jupyter notebook: [kaggle-sf-crime-data-exploration.ipynb](kaggle-sf-crime-data-exploration.ipynb)\n",
    "- This dataset suffers from **imbalanced classes** (**TREA** has 6 occurrences while **LARCENY/THEFT** has 1,749,000 occurrences)\n",
    "    - There are a couple ways to deal with imbalanced classes, such as:\n",
    "        - Changing performance metric (Do not use accuracy, use a confusion matrix, precision, recall, F1 score, ROC curves)\n",
    "        - Resample dataset (Oversample under-represented classes, and undersample over-represented classes)\n",
    "        - Try different ML algorithms that can handle imbalanced classes\n",
    "            - Decision Trees (Random Forests/XGBoost) often perform well on imbalanced classes (due to splitting rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:22.460838Z",
     "start_time": "2018-09-15T00:10:22.438200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>WARRANT ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-13 23:33:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>VANNESS AV / GREENWICH ST</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1500 Block of LOMBARD ST</td>\n",
       "      <td>-122.426995</td>\n",
       "      <td>37.800873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>PARK</td>\n",
       "      <td>NONE</td>\n",
       "      <td>100 Block of BRODERICK ST</td>\n",
       "      <td>-122.438738</td>\n",
       "      <td>37.771541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM UNLOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0 Block of TEDDY AV</td>\n",
       "      <td>-122.403252</td>\n",
       "      <td>37.713431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>VEHICLE THEFT</td>\n",
       "      <td>STOLEN AUTOMOBILE</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>AVALON AV / PERU AV</td>\n",
       "      <td>-122.423327</td>\n",
       "      <td>37.725138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>VEHICLE THEFT</td>\n",
       "      <td>STOLEN AUTOMOBILE</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>NONE</td>\n",
       "      <td>KIRKWOOD AV / DONAHUE ST</td>\n",
       "      <td>-122.371274</td>\n",
       "      <td>37.727564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dates        Category                        Descript  \\\n",
       "0  2015-05-13 23:53:00        WARRANTS                  WARRANT ARREST   \n",
       "1  2015-05-13 23:53:00  OTHER OFFENSES        TRAFFIC VIOLATION ARREST   \n",
       "2  2015-05-13 23:33:00  OTHER OFFENSES        TRAFFIC VIOLATION ARREST   \n",
       "3  2015-05-13 23:30:00   LARCENY/THEFT    GRAND THEFT FROM LOCKED AUTO   \n",
       "4  2015-05-13 23:30:00   LARCENY/THEFT    GRAND THEFT FROM LOCKED AUTO   \n",
       "5  2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM UNLOCKED AUTO   \n",
       "6  2015-05-13 23:30:00   VEHICLE THEFT               STOLEN AUTOMOBILE   \n",
       "7  2015-05-13 23:30:00   VEHICLE THEFT               STOLEN AUTOMOBILE   \n",
       "\n",
       "   DayOfWeek PdDistrict      Resolution                    Address  \\\n",
       "0  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "1  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "2  Wednesday   NORTHERN  ARREST, BOOKED  VANNESS AV / GREENWICH ST   \n",
       "3  Wednesday   NORTHERN            NONE   1500 Block of LOMBARD ST   \n",
       "4  Wednesday       PARK            NONE  100 Block of BRODERICK ST   \n",
       "5  Wednesday  INGLESIDE            NONE        0 Block of TEDDY AV   \n",
       "6  Wednesday  INGLESIDE            NONE        AVALON AV / PERU AV   \n",
       "7  Wednesday    BAYVIEW            NONE   KIRKWOOD AV / DONAHUE ST   \n",
       "\n",
       "            X          Y  \n",
       "0 -122.425892  37.774599  \n",
       "1 -122.425892  37.774599  \n",
       "2 -122.424363  37.800414  \n",
       "3 -122.426995  37.800873  \n",
       "4 -122.438738  37.771541  \n",
       "5 -122.403252  37.713431  \n",
       "6 -122.423327  37.725138  \n",
       "7 -122.371274  37.727564  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:22.468060Z",
     "start_time": "2018-09-15T00:10:22.462799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Dates', 'Category', 'Descript', 'DayOfWeek', 'PdDistrict',\n",
       "       'Resolution', 'Address', 'X', 'Y'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:22.772448Z",
     "start_time": "2018-09-15T00:10:22.469783Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2568495/1066574219.py:2: FutureWarning: null_counts is deprecated. Use show_counts instead\n",
      "  train_df.info(verbose=True, null_counts=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 878049 entries, 0 to 878048\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   Dates       878049 non-null  object \n",
      " 1   Category    878049 non-null  object \n",
      " 2   Descript    878049 non-null  object \n",
      " 3   DayOfWeek   878049 non-null  object \n",
      " 4   PdDistrict  878049 non-null  object \n",
      " 5   Resolution  878049 non-null  object \n",
      " 6   Address     878049 non-null  object \n",
      " 7   X           878049 non-null  float64\n",
      " 8   Y           878049 non-null  float64\n",
      "dtypes: float64(2), object(7)\n",
      "memory usage: 60.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# set show nulls to True\n",
    "train_df.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "### Things we learned thus far:\n",
    "\n",
    "- 878,049 instances in training set (or recorded crime instances in SF)\n",
    "- 9 columns (8 potential features + 1 label (Category))\n",
    "- Data types:\n",
    "    - 2 columns with float values\n",
    "    - 7 objects\n",
    "- There are no null (NaN) values (Yay!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:22.891578Z",
     "start_time": "2018-09-15T00:10:22.791301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LARCENY/THEFT                  174900\n",
       "OTHER OFFENSES                 126182\n",
       "NON-CRIMINAL                    92304\n",
       "ASSAULT                         76876\n",
       "DRUG/NARCOTIC                   53971\n",
       "VEHICLE THEFT                   53781\n",
       "VANDALISM                       44725\n",
       "WARRANTS                        42214\n",
       "BURGLARY                        36755\n",
       "SUSPICIOUS OCC                  31414\n",
       "MISSING PERSON                  25989\n",
       "ROBBERY                         23000\n",
       "FRAUD                           16679\n",
       "FORGERY/COUNTERFEITING          10609\n",
       "SECONDARY CODES                  9985\n",
       "WEAPON LAWS                      8555\n",
       "PROSTITUTION                     7484\n",
       "TRESPASS                         7326\n",
       "STOLEN PROPERTY                  4540\n",
       "SEX OFFENSES FORCIBLE            4388\n",
       "DISORDERLY CONDUCT               4320\n",
       "DRUNKENNESS                      4280\n",
       "RECOVERED VEHICLE                3138\n",
       "KIDNAPPING                       2341\n",
       "DRIVING UNDER THE INFLUENCE      2268\n",
       "RUNAWAY                          1946\n",
       "LIQUOR LAWS                      1903\n",
       "ARSON                            1513\n",
       "LOITERING                        1225\n",
       "EMBEZZLEMENT                     1166\n",
       "SUICIDE                           508\n",
       "FAMILY OFFENSES                   491\n",
       "BAD CHECKS                        406\n",
       "BRIBERY                           289\n",
       "EXTORTION                         256\n",
       "SEX OFFENSES NON FORCIBLE         148\n",
       "GAMBLING                          146\n",
       "PORNOGRAPHY/OBSCENE MAT            22\n",
       "TREA                                6\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Count number of observations for each crime \n",
    "train_df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:22.992868Z",
     "start_time": "2018-09-15T00:10:22.893918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SOUTHERN      157182\n",
       "MISSION       119908\n",
       "NORTHERN      105296\n",
       "BAYVIEW        89431\n",
       "CENTRAL        85460\n",
       "TENDERLOIN     81809\n",
       "INGLESIDE      78845\n",
       "TARAVAL        65596\n",
       "PARK           49313\n",
       "RICHMOND       45209\n",
       "Name: PdDistrict, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Count number of observations of crime for each PD District\n",
    "train_df['PdDistrict'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:23.086159Z",
     "start_time": "2018-09-15T00:10:22.995288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Friday       133734\n",
       "Wednesday    129211\n",
       "Saturday     126810\n",
       "Thursday     125038\n",
       "Tuesday      124965\n",
       "Monday       121584\n",
       "Sunday       116707\n",
       "Name: DayOfWeek, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Count number of observations for each day of week\n",
    "train_df['DayOfWeek'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:23.187282Z",
     "start_time": "2018-09-15T00:10:23.088498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NONE                                      526790\n",
       "ARREST, BOOKED                            206403\n",
       "ARREST, CITED                              77004\n",
       "LOCATED                                    17101\n",
       "PSYCHOPATHIC CASE                          14534\n",
       "UNFOUNDED                                   9585\n",
       "JUVENILE BOOKED                             5564\n",
       "COMPLAINANT REFUSES TO PROSECUTE            3976\n",
       "DISTRICT ATTORNEY REFUSES TO PROSECUTE      3934\n",
       "NOT PROSECUTED                              3714\n",
       "JUVENILE CITED                              3332\n",
       "PROSECUTED BY OUTSIDE AGENCY                2504\n",
       "EXCEPTIONAL CLEARANCE                       1530\n",
       "JUVENILE ADMONISHED                         1455\n",
       "JUVENILE DIVERTED                            355\n",
       "CLEARED-CONTACT JUVENILE FOR MORE INFO       217\n",
       "PROSECUTED FOR LESSER OFFENSE                 51\n",
       "Name: Resolution, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Count number of observations for Resolution feature\n",
    "train_df['Resolution'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:23.339069Z",
     "start_time": "2018-09-15T00:10:23.189621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-122.422616</td>\n",
       "      <td>37.771020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.030354</td>\n",
       "      <td>0.456893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-122.513642</td>\n",
       "      <td>37.707879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-122.432952</td>\n",
       "      <td>37.752427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-122.416420</td>\n",
       "      <td>37.775421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-122.406959</td>\n",
       "      <td>37.784369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-120.500000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   X              Y\n",
       "count  878049.000000  878049.000000\n",
       "mean     -122.422616      37.771020\n",
       "std         0.030354       0.456893\n",
       "min      -122.513642      37.707879\n",
       "25%      -122.432952      37.752427\n",
       "50%      -122.416420      37.775421\n",
       "75%      -122.406959      37.784369\n",
       "max      -120.500000      90.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['X','Y']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There seems to be an invalid coordinates (max) 90 (latitude) or -120.5 (longitude) does not seem to be a valid coordinate in San Francisco. We must fix these values for this feature.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "- Data cleaning\n",
    "    - imputation or removal of outlier values\n",
    "- Feature Engineering (Feature Creation)\n",
    "- Feature Encoding\n",
    "    - **Integer encode** or **label encode** ordinal categorical features that maintain order (Year, Business Quarter, Block/Street Number)\n",
    "    - Usually: \n",
    "        - **One hot encode** nominal categorical features (DayOfWeek, PdDistrict, StreetType, Category)\n",
    "            - mainly for logistic regression\n",
    "        - However, Random Forests & Boosting algorithms can handle nominal categorical features directly, so we just **integer encode** these features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "- Data removal\n",
    "- Data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:23.382595Z",
     "start_time": "2018-09-15T00:10:23.341391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>660485</th>\n",
       "      <td>2005-12-30 17:00:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Friday</td>\n",
       "      <td>TENDERLOIN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>5THSTNORTH ST / OFARRELL ST</td>\n",
       "      <td>-120.5</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660711</th>\n",
       "      <td>2005-12-30 00:34:00</td>\n",
       "      <td>ASSAULT</td>\n",
       "      <td>INFLICT INJURY ON COHABITEE</td>\n",
       "      <td>Friday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>JAMESLICKFREEWAY HY / SILVER AV</td>\n",
       "      <td>-120.5</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660712</th>\n",
       "      <td>2005-12-30 00:34:00</td>\n",
       "      <td>ASSAULT</td>\n",
       "      <td>AGGRAVATED ASSAULT WITH BODILY FORCE</td>\n",
       "      <td>Friday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>JAMESLICKFREEWAY HY / SILVER AV</td>\n",
       "      <td>-120.5</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661106</th>\n",
       "      <td>2005-12-29 00:07:00</td>\n",
       "      <td>NON-CRIMINAL</td>\n",
       "      <td>AIDED CASE, MENTAL DISTURBED</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>TENDERLOIN</td>\n",
       "      <td>PSYCHOPATHIC CASE</td>\n",
       "      <td>5THSTNORTH ST / EDDY ST</td>\n",
       "      <td>-120.5</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666430</th>\n",
       "      <td>2005-11-30 11:25:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>TENDERLOIN</td>\n",
       "      <td>ARREST, CITED</td>\n",
       "      <td>5THSTNORTH ST / ELLIS ST</td>\n",
       "      <td>-120.5</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844995</th>\n",
       "      <td>2003-06-11 08:49:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>DRIVERS LICENSE, SUSPENDED OR REVOKED</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>ARREST, CITED</td>\n",
       "      <td>JAMES LICK FREEWAY HY / CESAR CHAVEZ ST</td>\n",
       "      <td>-120.5</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845842</th>\n",
       "      <td>2003-06-09 09:25:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>DRIVERS LICENSE, SUSPENDED OR REVOKED</td>\n",
       "      <td>Monday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>ARREST, CITED</td>\n",
       "      <td>JAMES LICK FREEWAY HY / CESAR CHAVEZ ST</td>\n",
       "      <td>-120.5</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852880</th>\n",
       "      <td>2003-05-02 01:00:00</td>\n",
       "      <td>SEX OFFENSES FORCIBLE</td>\n",
       "      <td>FORCIBLE RAPE, BODILY FORCE</td>\n",
       "      <td>Friday</td>\n",
       "      <td>SOUTHERN</td>\n",
       "      <td>COMPLAINANT REFUSES TO PROSECUTE</td>\n",
       "      <td>3RD ST / JAMES LICK FREEWAY HY</td>\n",
       "      <td>-120.5</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857248</th>\n",
       "      <td>2003-04-14 16:30:00</td>\n",
       "      <td>ROBBERY</td>\n",
       "      <td>ROBBERY ON THE STREET, STRONGARM</td>\n",
       "      <td>Monday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>COMPLAINANT REFUSES TO PROSECUTE</td>\n",
       "      <td>GILMAN AV / FITCH ST</td>\n",
       "      <td>-120.5</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871198</th>\n",
       "      <td>2003-02-05 12:00:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>PETTY THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>SOUTHERN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>SPEAR ST / THE EMBARCADERO SOUTH ST</td>\n",
       "      <td>-120.5</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Dates               Category  \\\n",
       "660485  2005-12-30 17:00:00          LARCENY/THEFT   \n",
       "660711  2005-12-30 00:34:00                ASSAULT   \n",
       "660712  2005-12-30 00:34:00                ASSAULT   \n",
       "661106  2005-12-29 00:07:00           NON-CRIMINAL   \n",
       "666430  2005-11-30 11:25:00         OTHER OFFENSES   \n",
       "...                     ...                    ...   \n",
       "844995  2003-06-11 08:49:00         OTHER OFFENSES   \n",
       "845842  2003-06-09 09:25:00         OTHER OFFENSES   \n",
       "852880  2003-05-02 01:00:00  SEX OFFENSES FORCIBLE   \n",
       "857248  2003-04-14 16:30:00                ROBBERY   \n",
       "871198  2003-02-05 12:00:00          LARCENY/THEFT   \n",
       "\n",
       "                                     Descript  DayOfWeek  PdDistrict  \\\n",
       "660485           GRAND THEFT FROM LOCKED AUTO     Friday  TENDERLOIN   \n",
       "660711            INFLICT INJURY ON COHABITEE     Friday     BAYVIEW   \n",
       "660712   AGGRAVATED ASSAULT WITH BODILY FORCE     Friday     BAYVIEW   \n",
       "661106           AIDED CASE, MENTAL DISTURBED   Thursday  TENDERLOIN   \n",
       "666430                      TRAFFIC VIOLATION  Wednesday  TENDERLOIN   \n",
       "...                                       ...        ...         ...   \n",
       "844995  DRIVERS LICENSE, SUSPENDED OR REVOKED  Wednesday   INGLESIDE   \n",
       "845842  DRIVERS LICENSE, SUSPENDED OR REVOKED     Monday   INGLESIDE   \n",
       "852880            FORCIBLE RAPE, BODILY FORCE     Friday    SOUTHERN   \n",
       "857248       ROBBERY ON THE STREET, STRONGARM     Monday     BAYVIEW   \n",
       "871198           PETTY THEFT FROM LOCKED AUTO  Wednesday    SOUTHERN   \n",
       "\n",
       "                              Resolution  \\\n",
       "660485                              NONE   \n",
       "660711                    ARREST, BOOKED   \n",
       "660712                    ARREST, BOOKED   \n",
       "661106                 PSYCHOPATHIC CASE   \n",
       "666430                     ARREST, CITED   \n",
       "...                                  ...   \n",
       "844995                     ARREST, CITED   \n",
       "845842                     ARREST, CITED   \n",
       "852880  COMPLAINANT REFUSES TO PROSECUTE   \n",
       "857248  COMPLAINANT REFUSES TO PROSECUTE   \n",
       "871198                              NONE   \n",
       "\n",
       "                                        Address      X     Y  \n",
       "660485              5THSTNORTH ST / OFARRELL ST -120.5  90.0  \n",
       "660711          JAMESLICKFREEWAY HY / SILVER AV -120.5  90.0  \n",
       "660712          JAMESLICKFREEWAY HY / SILVER AV -120.5  90.0  \n",
       "661106                  5THSTNORTH ST / EDDY ST -120.5  90.0  \n",
       "666430                 5THSTNORTH ST / ELLIS ST -120.5  90.0  \n",
       "...                                         ...    ...   ...  \n",
       "844995  JAMES LICK FREEWAY HY / CESAR CHAVEZ ST -120.5  90.0  \n",
       "845842  JAMES LICK FREEWAY HY / CESAR CHAVEZ ST -120.5  90.0  \n",
       "852880           3RD ST / JAMES LICK FREEWAY HY -120.5  90.0  \n",
       "857248                     GILMAN AV / FITCH ST -120.5  90.0  \n",
       "871198      SPEAR ST / THE EMBARCADERO SOUTH ST -120.5  90.0  \n",
       "\n",
       "[67 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['Y'] == train_df['Y'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I notice that there are 108 rows with incorrect coordinates, and they seem to be the exact same two coordinates (90, -120.5). There are many ways to handle this. We need to do data imputation, which can be done several ways. For now, I will randomly sample from a normal distribution with the range of a standard deviation from the mean. However, I could use a linear regression model to predict the latitude and longitude values (based on other variables such as PD district?) and use that to impute the bad / inconsistent data points.\n",
    "\n",
    "Another method is to completely remove this data. Since I already have a lot of data, and I do not want this incorrect data to affect my results, I could remove them. However, I will stick with data imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:23.415432Z",
     "start_time": "2018-09-15T00:10:23.385191Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df['Y'].replace(to_replace= train_df['Y'].max() ,value=np.nan, inplace=True)\n",
    "train_df['X'].replace(to_replace= train_df['X'].max() ,value=np.nan, inplace=True)\n",
    "test_df['Y'].replace(to_replace= test_df['Y'].max() ,value=np.nan, inplace=True)\n",
    "test_df['X'].replace(to_replace= test_df['X'].max() ,value=np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:23.917984Z",
     "start_time": "2018-09-15T00:10:23.417166Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dates          0\n",
       "Category       0\n",
       "Descript       0\n",
       "DayOfWeek      0\n",
       "PdDistrict     0\n",
       "Resolution     0\n",
       "Address        0\n",
       "X             67\n",
       "Y             67\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:24.145140Z",
     "start_time": "2018-09-15T00:10:23.920445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id             0\n",
       "Dates          0\n",
       "DayOfWeek      0\n",
       "PdDistrict     0\n",
       "Address        0\n",
       "X             76\n",
       "Y             76\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:24.366520Z",
     "start_time": "2018-09-15T00:10:24.147409Z"
    }
   },
   "outputs": [],
   "source": [
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    mean_X = dataset[\"X\"].mean()\n",
    "    std_X = dataset[\"X\"].std()\n",
    "    mean_Y = dataset[\"Y\"].mean()\n",
    "    std_Y = dataset[\"Y\"].std()\n",
    "    max_X = mean_X + std_X\n",
    "    min_X = mean_X - std_X\n",
    "    max_Y = mean_Y + std_Y\n",
    "    min_Y = mean_Y - std_Y\n",
    "\n",
    "    # Both X and Y will have the same null so just use Y\n",
    "    is_null = dataset['Y'].isnull().sum()\n",
    "    # randomly sample float numbers within a range from a uniform distribution\n",
    "#     random_X = (max_X - min_X) * np.random.random_sample(size = is_null) + min_X\n",
    "#     random_Y = (max_Y - min_Y) * np.random.random_sample(size = is_null) + min_Y\n",
    "    # randomly sample float numbers within a range from a normal distribution\n",
    "    random_X = (max_X - min_X) * np.random.randn(is_null) + min_X\n",
    "    random_Y = (max_Y - min_Y) * np.random.randn(is_null) + min_Y\n",
    "\n",
    "    X_slice = dataset['X'].copy()\n",
    "    Y_slice = dataset['Y'].copy()\n",
    "    X_slice[np.isnan(X_slice)] = random_X\n",
    "    Y_slice[np.isnan(Y_slice)] = random_Y\n",
    "    dataset['X'] = X_slice\n",
    "    dataset['Y'] = Y_slice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:24.551483Z",
     "start_time": "2018-09-15T00:10:24.368883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-122.422765</td>\n",
       "      <td>37.767032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.025289</td>\n",
       "      <td>0.024169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-122.552543</td>\n",
       "      <td>37.626999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-122.432952</td>\n",
       "      <td>37.752427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-122.416422</td>\n",
       "      <td>37.775421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-122.406959</td>\n",
       "      <td>37.784368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-122.310043</td>\n",
       "      <td>37.843857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   X              Y\n",
       "count  878049.000000  878049.000000\n",
       "mean     -122.422765      37.767032\n",
       "std         0.025289       0.024169\n",
       "min      -122.552543      37.626999\n",
       "25%      -122.432952      37.752427\n",
       "50%      -122.416422      37.775421\n",
       "75%      -122.406959      37.784368\n",
       "max      -122.310043      37.843857"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['X', 'Y']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:24.558034Z",
     "start_time": "2018-09-15T00:10:24.553530Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878049"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:24.757891Z",
     "start_time": "2018-09-15T00:10:24.560297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>884262.000000</td>\n",
       "      <td>884262.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-122.422860</td>\n",
       "      <td>37.766985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.025349</td>\n",
       "      <td>0.024183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-122.542337</td>\n",
       "      <td>37.616128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-122.433075</td>\n",
       "      <td>37.752360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-122.416517</td>\n",
       "      <td>37.775421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-122.406959</td>\n",
       "      <td>37.784353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-122.283036</td>\n",
       "      <td>37.890869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   X              Y\n",
       "count  884262.000000  884262.000000\n",
       "mean     -122.422860      37.766985\n",
       "std         0.025349       0.024183\n",
       "min      -122.542337      37.616128\n",
       "25%      -122.433075      37.752360\n",
       "50%      -122.416517      37.775421\n",
       "75%      -122.406959      37.784353\n",
       "max      -122.283036      37.890869"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[['X', 'Y']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:24.765879Z",
     "start_time": "2018-09-15T00:10:24.760906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "884262"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "- Let's create some new features from the data that exists in the current feature space\n",
    "- There are a couple categories of features:\n",
    "    - Temporal features\n",
    "    - Spatial features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Features\n",
    "We want to have a column for Time, so we must parse through the 'Dates' feature to create the 'Time' feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:25.274601Z",
     "start_time": "2018-09-15T00:10:24.768516Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transform the Date into a python datetime object.\n",
    "train_df[\"Dates\"] = pd.to_datetime(train_df[\"Dates\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "test_df[\"Dates\"] = pd.to_datetime(test_df[\"Dates\"], format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:31.564182Z",
     "start_time": "2018-09-15T00:10:25.277052Z"
    }
   },
   "outputs": [],
   "source": [
    "# Minute\n",
    "train_df[\"Minute\"] = train_df[\"Dates\"].map(lambda x: x.minute)\n",
    "test_df[\"Minute\"] = test_df[\"Dates\"].map(lambda x: x.minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:37.693960Z",
     "start_time": "2018-09-15T00:10:31.566084Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hour\n",
    "train_df[\"Hour\"] = train_df[\"Dates\"].map(lambda x: x.hour)\n",
    "test_df[\"Hour\"] = test_df[\"Dates\"].map(lambda x: x.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:43.874460Z",
     "start_time": "2018-09-15T00:10:37.696280Z"
    }
   },
   "outputs": [],
   "source": [
    "# Day\n",
    "train_df[\"Day\"] = train_df[\"Dates\"].map(lambda x: x.day)\n",
    "test_df[\"Day\"] = test_df[\"Dates\"].map(lambda x: x.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:49.946466Z",
     "start_time": "2018-09-15T00:10:43.876358Z"
    }
   },
   "outputs": [],
   "source": [
    "# Month\n",
    "train_df[\"Month\"] = train_df[\"Dates\"].map(lambda x: x.month)\n",
    "test_df[\"Month\"] = test_df[\"Dates\"].map(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:55.794134Z",
     "start_time": "2018-09-15T00:10:49.948660Z"
    }
   },
   "outputs": [],
   "source": [
    "# Year\n",
    "train_df[\"Year\"] = train_df[\"Dates\"].map(lambda x: x.year)\n",
    "test_df[\"Year\"] = test_df[\"Dates\"].map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:10:56.787121Z",
     "start_time": "2018-09-15T00:10:55.796072Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Hour Zone 0 - Pass midnight, 1 - morning, 2 - afternoon, 3 - dinner / sun set, 4 - night\n",
    "# def get_hour_zone(hour):\n",
    "#     if hour >= 2 and hour < 8: \n",
    "#         return 0\n",
    "#     elif hour >= 8 and hour < 12: \n",
    "#         return 1\n",
    "#     elif hour >= 12 and hour < 18: \n",
    "#         return 2\n",
    "#     elif hour >= 18 and hour < 22: \n",
    "#         return 3\n",
    "#     elif hour < 2 or hour >= 22: \n",
    "#         return 4\n",
    "    \n",
    "# train_df[\"Hour_Zone\"] = train_df[\"Hour\"].map(get_hour_zone)\n",
    "# test_df[\"Hour_Zone\"] = test_df[\"Hour\"].map(get_hour_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:03.922991Z",
     "start_time": "2018-09-15T00:10:56.789255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n"
     ]
    }
   ],
   "source": [
    "# Add Week of Year\n",
    "train_df[\"WeekOfYear\"] = train_df[\"Dates\"].map(lambda x: int(x.weekofyear / 2) - 1)\n",
    "test_df[\"WeekOfYear\"] = test_df[\"Dates\"].map(lambda x: int(x.weekofyear / 2))\n",
    "\n",
    "print(sorted(train_df['WeekOfYear'].unique()))\n",
    "print(sorted(test_df['WeekOfYear'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:03.944540Z",
     "start_time": "2018-09-15T00:11:03.925176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>WeekOfYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>WARRANT ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-13 23:33:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>VANNESS AV / GREENWICH ST</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800414</td>\n",
       "      <td>33</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1500 Block of LOMBARD ST</td>\n",
       "      <td>-122.426995</td>\n",
       "      <td>37.800873</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>PARK</td>\n",
       "      <td>NONE</td>\n",
       "      <td>100 Block of BRODERICK ST</td>\n",
       "      <td>-122.438738</td>\n",
       "      <td>37.771541</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dates        Category                      Descript  \\\n",
       "0 2015-05-13 23:53:00        WARRANTS                WARRANT ARREST   \n",
       "1 2015-05-13 23:53:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "2 2015-05-13 23:33:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "3 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "4 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "\n",
       "   DayOfWeek PdDistrict      Resolution                    Address  \\\n",
       "0  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "1  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "2  Wednesday   NORTHERN  ARREST, BOOKED  VANNESS AV / GREENWICH ST   \n",
       "3  Wednesday   NORTHERN            NONE   1500 Block of LOMBARD ST   \n",
       "4  Wednesday       PARK            NONE  100 Block of BRODERICK ST   \n",
       "\n",
       "            X          Y  Minute  Hour  Day  Month  Year  WeekOfYear  \n",
       "0 -122.425892  37.774599      53    23   13      5  2015           9  \n",
       "1 -122.425892  37.774599      53    23   13      5  2015           9  \n",
       "2 -122.424363  37.800414      33    23   13      5  2015           9  \n",
       "3 -122.426995  37.800873      30    23   13      5  2015           9  \n",
       "4 -122.438738  37.771541      30    23   13      5  2015           9  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holiday Feature\n",
    "\n",
    "- Certain crimes may be more apparent on holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:04.369855Z",
     "start_time": "2018-09-15T00:11:03.946433Z"
    }
   },
   "outputs": [],
   "source": [
    "# from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "\n",
    "# # Training set\n",
    "# cal = calendar()\n",
    "# holidays = cal.holidays(start=train_df['Dates'].min(), end=train_df['Dates'].max())\n",
    "# train_df['Holiday'] = train_df['Dates'].dt.date.astype('datetime64').isin(holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:04.784067Z",
     "start_time": "2018-09-15T00:11:04.372197Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Test set\n",
    "# cal = calendar()\n",
    "# holidays = cal.holidays(start=test_df['Dates'].min(), end=test_df['Dates'].max())\n",
    "# test_df['Holiday'] = test_df['Dates'].dt.date.astype('datetime64').isin(holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:04.885777Z",
     "start_time": "2018-09-15T00:11:04.786072Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(train_df[train_df['Holiday'] == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:04.993193Z",
     "start_time": "2018-09-15T00:11:04.888127Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(test_df[test_df['Holiday'] == True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Hours Feature\n",
    "\n",
    "- There should be an effect of business hours on the type of crime committed\n",
    "- Let's create a binary feature where:\n",
    "    - 1 is typical business hours [8:00AM - 6:00PM]\n",
    "    - 0 is not business hours [6:01PM - 7:59 AM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:12.059178Z",
     "start_time": "2018-09-15T00:11:04.995075Z"
    }
   },
   "outputs": [],
   "source": [
    "# from datetime import datetime, time\n",
    "\n",
    "# def time_in_range(start, end, x):\n",
    "#     \"\"\"Return true if x is in the inclusive range [start, end]\"\"\"\n",
    "#     if start <= end:\n",
    "#         return start <= x <= end\n",
    "#     else:\n",
    "#         return start <= x or x <= end\n",
    "\n",
    "# def map_business_hours(date):\n",
    "    \n",
    "#     # Convert military time to AM & PM\n",
    "#     time_parsed = date.time()\n",
    "#     business_start = time(8, 0, 0)\n",
    "#     business_end = time(18, 0, 0)\n",
    "    \n",
    "#     if time_in_range(business_start, business_end, time_parsed):\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "    \n",
    "# train_df['BusinessHour'] = train_df['Dates'].map(map_business_hours).astype('uint8')\n",
    "# test_df['BusinessHour'] = test_df['Dates'].map(map_business_hours).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:12.078593Z",
     "start_time": "2018-09-15T00:11:12.061166Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_df['BusinessHour'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:12.102491Z",
     "start_time": "2018-09-15T00:11:12.082130Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Quarter (Removed)\n",
    "\n",
    "- Business Quarter might have an effect on what types of crimes are commited\n",
    "- Q1 = 1 (Jan. - March) Q2 = 2 (April - June), Q3 = 3 (July - Sept.), Q4 = 4 (Oct. - Dec.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:12.108233Z",
     "start_time": "2018-09-15T00:11:12.104172Z"
    }
   },
   "outputs": [],
   "source": [
    "# def map_business_quarter(month):\n",
    "    \n",
    "#     if month in [1, 2, 3]:\n",
    "# #         print(time_parsed)\n",
    "#         return 1\n",
    "#     elif month in [4, 5, 6]:\n",
    "#         return 2\n",
    "#     elif month in [7, 8, 9]:\n",
    "#         return 3\n",
    "#     elif month in [10, 11, 12]:\n",
    "#         return 4\n",
    "    \n",
    "# train_df['Quarter'] = train_df['Month'].map(map_business_quarter)\n",
    "# test_df['Quarter'] = test_df['Month'].map(map_business_quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:12.113726Z",
     "start_time": "2018-09-15T00:11:12.110576Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_df['Quarter'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:12.119440Z",
     "start_time": "2018-09-15T00:11:12.116998Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Season\n",
    "\n",
    "The season feature may affect what type of crimes are commited. \n",
    "- 1 = Winter, 2 = Spring, 3 = Summer, 4 = Fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:12.174037Z",
     "start_time": "2018-09-15T00:11:12.121921Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_df['Season']=(train_df['Month']%12 + 3)//3\n",
    "# test_df['Season']=(test_df['Month']%12 + 3)//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:12.193165Z",
     "start_time": "2018-09-15T00:11:12.175930Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekend\n",
    "\n",
    "- Weekends may have effect on what types of crimes are commmited\n",
    "- Weekday = 0, Weekend =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:12.984924Z",
     "start_time": "2018-09-15T00:11:12.195523Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Weekend Feature\n",
    "\n",
    "# # Weekday = 0, Weekend = 1\n",
    "# days = {'Monday':0 ,'Tuesday':0 ,'Wednesday':0 ,'Thursday':0 ,'Friday':0, 'Saturday':1 ,'Sunday':1}\n",
    "\n",
    "# train_df['Weekend'] = train_df['DayOfWeek'].replace(days).astype('uint8')\n",
    "# test_df['Weekend'] = test_df['DayOfWeek'].replace(days).astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Street Type\n",
    "\n",
    "The street type can have an effect on what type of crime is committed, so we want to extract the street type from the 'Address' feature.\n",
    "\n",
    "We have avenues, streets, ways, boulevards, highways, courts, walks, plazas, and differet number of intersections of roads/streets (Addresses with /)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:13.197395Z",
     "start_time": "2018-09-15T00:11:12.986765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['800 Block of BRYANT ST', '800 Block of MARKET ST',\n",
       "       '2000 Block of MISSION ST', '1000 Block of POTRERO AV',\n",
       "       '900 Block of MARKET ST', '0 Block of TURK ST', '0 Block of 6TH ST',\n",
       "       '300 Block of ELLIS ST', '400 Block of ELLIS ST',\n",
       "       '16TH ST / MISSION ST',\n",
       "       ...\n",
       "       '5TH AV / CALIFORNIA ST', 'HAZELWOOD AV / YERBABUENA AV',\n",
       "       '0 Block of TROY AL', '900 Block of MARTIN LUTHER KING JR DR',\n",
       "       'CLIPPER ST / PORTOLA DR', 'PRECITA AV / CESAR CHAVEZ ST',\n",
       "       '0 Block of COLUSA PL', '2800 Block of KEITH ST',\n",
       "       'CABRILLO ST / ARGUELLO BL', 'OFARRELL ST / CYRIL MAGNIN ST'],\n",
       "      dtype='object', length=23228)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Address'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:17.624158Z",
     "start_time": "2018-09-15T00:11:13.199248Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_streets(address):\n",
    "    street_types = ['AV', 'ST', 'CT', 'PZ', 'LN', 'DR', 'PL', 'HY', \n",
    "                    'FY', 'WY', 'TR', 'RD', 'BL', 'WAY', 'CR', 'AL', 'I-80',  \n",
    "                    'RW', 'WK','EL CAMINO DEL MAR']\n",
    "    street_pattern = '|'.join(street_types)\n",
    "    streets = re.findall(street_pattern, address)\n",
    "    if len(streets) == 0:\n",
    "        # Debug\n",
    "#         print(address)\n",
    "        return 'OTHER'\n",
    "    elif len(streets) == 1:\n",
    "        return streets[0]\n",
    "    else:\n",
    "#         print(address)\n",
    "        return 'INT'\n",
    "\n",
    "train_df['StreetType'] = train_df['Address'].map(find_streets)\n",
    "test_df['StreetType'] = test_df['Address'].map(find_streets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:17.759847Z",
     "start_time": "2018-09-15T00:11:17.626318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INT                  389995\n",
       "ST                   358797\n",
       "AV                    92467\n",
       "BL                    13074\n",
       "DR                     8200\n",
       "WY                     4063\n",
       "RD                     2384\n",
       "PZ                     2347\n",
       "CT                     2059\n",
       "LN                     1356\n",
       "PL                      863\n",
       "HY                      819\n",
       "TR                      766\n",
       "I-80                    322\n",
       "CR                      291\n",
       "AL                      150\n",
       "WAY                      55\n",
       "EL CAMINO DEL MAR        21\n",
       "OTHER                    14\n",
       "WK                        5\n",
       "RW                        1\n",
       "Name: StreetType, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['StreetType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:17.808128Z",
     "start_time": "2018-09-15T00:11:17.762189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values\n",
    "train_df['StreetType'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:17.834744Z",
     "start_time": "2018-09-15T00:11:17.810033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>WeekOfYear</th>\n",
       "      <th>StreetType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>WARRANT ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-13 23:33:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>VANNESS AV / GREENWICH ST</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800414</td>\n",
       "      <td>33</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1500 Block of LOMBARD ST</td>\n",
       "      <td>-122.426995</td>\n",
       "      <td>37.800873</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>PARK</td>\n",
       "      <td>NONE</td>\n",
       "      <td>100 Block of BRODERICK ST</td>\n",
       "      <td>-122.438738</td>\n",
       "      <td>37.771541</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM UNLOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0 Block of TEDDY AV</td>\n",
       "      <td>-122.403252</td>\n",
       "      <td>37.713431</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>AV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>VEHICLE THEFT</td>\n",
       "      <td>STOLEN AUTOMOBILE</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>AVALON AV / PERU AV</td>\n",
       "      <td>-122.423327</td>\n",
       "      <td>37.725138</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>VEHICLE THEFT</td>\n",
       "      <td>STOLEN AUTOMOBILE</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>NONE</td>\n",
       "      <td>KIRKWOOD AV / DONAHUE ST</td>\n",
       "      <td>-122.371274</td>\n",
       "      <td>37.727564</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>INT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dates        Category                        Descript  \\\n",
       "0 2015-05-13 23:53:00        WARRANTS                  WARRANT ARREST   \n",
       "1 2015-05-13 23:53:00  OTHER OFFENSES        TRAFFIC VIOLATION ARREST   \n",
       "2 2015-05-13 23:33:00  OTHER OFFENSES        TRAFFIC VIOLATION ARREST   \n",
       "3 2015-05-13 23:30:00   LARCENY/THEFT    GRAND THEFT FROM LOCKED AUTO   \n",
       "4 2015-05-13 23:30:00   LARCENY/THEFT    GRAND THEFT FROM LOCKED AUTO   \n",
       "5 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM UNLOCKED AUTO   \n",
       "6 2015-05-13 23:30:00   VEHICLE THEFT               STOLEN AUTOMOBILE   \n",
       "7 2015-05-13 23:30:00   VEHICLE THEFT               STOLEN AUTOMOBILE   \n",
       "\n",
       "   DayOfWeek PdDistrict      Resolution                    Address  \\\n",
       "0  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "1  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "2  Wednesday   NORTHERN  ARREST, BOOKED  VANNESS AV / GREENWICH ST   \n",
       "3  Wednesday   NORTHERN            NONE   1500 Block of LOMBARD ST   \n",
       "4  Wednesday       PARK            NONE  100 Block of BRODERICK ST   \n",
       "5  Wednesday  INGLESIDE            NONE        0 Block of TEDDY AV   \n",
       "6  Wednesday  INGLESIDE            NONE        AVALON AV / PERU AV   \n",
       "7  Wednesday    BAYVIEW            NONE   KIRKWOOD AV / DONAHUE ST   \n",
       "\n",
       "            X          Y  Minute  Hour  Day  Month  Year  WeekOfYear  \\\n",
       "0 -122.425892  37.774599      53    23   13      5  2015           9   \n",
       "1 -122.425892  37.774599      53    23   13      5  2015           9   \n",
       "2 -122.424363  37.800414      33    23   13      5  2015           9   \n",
       "3 -122.426995  37.800873      30    23   13      5  2015           9   \n",
       "4 -122.438738  37.771541      30    23   13      5  2015           9   \n",
       "5 -122.403252  37.713431      30    23   13      5  2015           9   \n",
       "6 -122.423327  37.725138      30    23   13      5  2015           9   \n",
       "7 -122.371274  37.727564      30    23   13      5  2015           9   \n",
       "\n",
       "  StreetType  \n",
       "0        INT  \n",
       "1        INT  \n",
       "2        INT  \n",
       "3        INT  \n",
       "4         ST  \n",
       "5         AV  \n",
       "6        INT  \n",
       "7        INT  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block Features (Removed)\n",
    "\n",
    "- Let's explore and create the block feature, since we saw it a lot in the address features\n",
    "- Binary feature\n",
    "    - Categorize address that contains 'Block', as having a block, and if no block exists, we will assign to 0.\n",
    "- 617231 addresses with blocks\n",
    "- 260818 addresses with no blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:17.840253Z",
     "start_time": "2018-09-15T00:11:17.836605Z"
    }
   },
   "outputs": [],
   "source": [
    "# def find_block(address):\n",
    "#     block_pattern = 'Block'\n",
    "#     blocks = re.search(block_pattern, address)\n",
    "#     if blocks:\n",
    "# #         print(address)\n",
    "#         return 1\n",
    "#     else:\n",
    "# #         print(address)\n",
    "#         return 0\n",
    "\n",
    "\n",
    "# train_df['Block'] = train_df['Address'].map(find_block)\n",
    "# test_df['Block'] = test_df['Address'].map(find_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:17.844279Z",
     "start_time": "2018-09-15T00:11:17.842121Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_df['Block'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block Number Feature\n",
    "\n",
    "- Let's explore the block number from address\n",
    "- Block number has ordinal data type (order matters), and has spatial significance\n",
    "- It seems all the block numbers are in intervals of 100\n",
    "- How to categorize\n",
    "    - Addresses that do not have a block number will be categorized as 0\n",
    "    - Addresses with block number will be divided by 100, and added by 1 for mapping (0 is saved for addresses with no block number)\n",
    "- 85 unique block numbers (including 1 where there is no block number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:21.837626Z",
     "start_time": "2018-09-15T00:11:17.846149Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_block_number(address):\n",
    "    block_num_pattern = '[0-9]+\\s[Block]'\n",
    "    block_num = re.search(block_num_pattern, address)\n",
    "    if block_num:\n",
    "#         print(address)\n",
    "        num_pattern = '[0-9]+'\n",
    "        block_no_pos = re.search(num_pattern, address)\n",
    "        # Get integer of found regular expression\n",
    "        block_no = int(block_no_pos.group())\n",
    "        # Convert block number by dividing by 100 and adding 1 (0 = addresses with no block)\n",
    "        block_map = (block_no // 100) + 1\n",
    "#         print(block_map)\n",
    "        return block_map\n",
    "    else:\n",
    "#         print(address)\n",
    "        # \n",
    "        return 0\n",
    "\n",
    "\n",
    "train_df['BlockNo'] = train_df['Address'].map(find_block_number)\n",
    "test_df['BlockNo'] = test_df['Address'].map(find_block_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:21.875408Z",
     "start_time": "2018-09-15T00:11:21.839834Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     260818\n",
       "1      76325\n",
       "2      51917\n",
       "9      51718\n",
       "3      38407\n",
       "       ...  \n",
       "82         7\n",
       "79         5\n",
       "81         4\n",
       "84         4\n",
       "80         3\n",
       "Name: BlockNo, Length: 85, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['BlockNo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X, Y Coordinates\n",
    "\n",
    "- Normalize and scale the X and Y coordinates\n",
    "- I use **K-Means clustering** to create a new feature for the longitude and latitude by grouping clusters of points based on Euclidean distances.\n",
    "- X = longitude, Y = latitude\n",
    "- I also extract more spatial features from the X, Y coordinates by transforming them from the cartesian space to the polar space ([Reference](https://www.kaggle.com/c/sf-crime/discussion/18853))\n",
    "    1. three variants of rotated Cartesian coordinates (rotated by 30, 45, 60 degree each) \n",
    "    2. Polar coordinates (i.e. the 'r' and the angle 'theta')\n",
    "    3. The approach makes some intuitive sense i.e. that having such features should help in extracting some more spatial information (than relying on the current x-y alone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:22.862516Z",
     "start_time": "2018-09-15T00:11:21.879241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 34309 unique longitude values, 34309 unique latitude values\n"
     ]
    }
   ],
   "source": [
    "# Normalize X and Y\n",
    "print('There are %d unique longitude values, %d unique latitude values' % (train_df['X'].nunique(), \n",
    "                                                                           train_df['Y'].nunique()))\n",
    "\n",
    "xy_scaler = StandardScaler().fit(train_df[['X', 'Y']])\n",
    "train_df[['X', 'Y']] = xy_scaler.transform(train_df[['X', 'Y']])\n",
    "test_df[['X', 'Y']] = xy_scaler.transform(test_df[['X', 'Y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:23.200903Z",
     "start_time": "2018-09-15T00:11:22.864443Z"
    }
   },
   "outputs": [],
   "source": [
    "# X-Y plane rotation and space transformation to extract more spatial information\n",
    "# 2-dimensional rotation based on below functions:\n",
    "# rotated x = xcos - ysin\n",
    "# rotated y = xsin + ycos\n",
    "# Conver from cartesian space -> polar space\n",
    "\n",
    "cos_30 = math.cos(math.radians(30))\n",
    "sin_30 = math.sin(math.radians(30))\n",
    "cos_45 = math.cos(math.radians(45))\n",
    "sin_45 = math.sin(math.radians(45))\n",
    "cos_60 = math.cos(math.radians(60))\n",
    "sin_60 = math.sin(math.radians(60))\n",
    "\n",
    "\n",
    "train_df[\"Rot30_X\"] = train_df['X'] * cos_30 - train_df['Y'] * sin_30 \n",
    "train_df[\"Rot30_Y\"] = train_df['X'] * sin_30 + train_df['Y'] * cos_30\n",
    "train_df[\"Rot45_X\"] = train_df['X'] * cos_45 - train_df['Y'] * sin_45  \n",
    "train_df[\"Rot45_Y\"] = train_df['X'] * sin_45 + train_df['Y'] * cos_45\n",
    "train_df[\"Rot60_X\"] = train_df['X'] * cos_60 - train_df['Y'] * sin_60  \n",
    "train_df[\"Rot60_Y\"] = train_df['X'] * sin_60 + train_df['Y'] * cos_60\n",
    "train_df[\"Radius\"] = np.sqrt(train_df['X'] ** 2 + train_df['Y'] ** 2)\n",
    "train_df[\"Angle\"] = np.arctan2(train_df['X'], train_df['Y'])\n",
    "\n",
    "test_df[\"Rot30_X\"] = test_df['X'] * cos_30 - test_df['Y'] * sin_30  \n",
    "test_df[\"Rot30_Y\"] = test_df['X'] * sin_30 + test_df['Y'] * cos_30\n",
    "test_df[\"Rot45_X\"] = test_df['X'] * cos_45 - test_df['Y'] * sin_45  \n",
    "test_df[\"Rot45_Y\"] = test_df['X'] * sin_45 + test_df['Y'] * cos_45\n",
    "test_df[\"Rot60_X\"] = test_df['X'] * cos_60 - test_df['Y'] * sin_60  \n",
    "test_df[\"Rot60_Y\"] = test_df['X'] * sin_60 + test_df['Y'] * cos_60\n",
    "test_df[\"Radius\"] = np.sqrt(test_df['X'] ** 2 + test_df['Y'] ** 2)\n",
    "test_df[\"Angle\"] = np.arctan2(test_df['X'], test_df['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:11:25.125720Z",
     "start_time": "2018-09-15T00:11:23.202875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>WeekOfYear</th>\n",
       "      <th>BlockNo</th>\n",
       "      <th>Rot30_X</th>\n",
       "      <th>Rot30_Y</th>\n",
       "      <th>Rot45_X</th>\n",
       "      <th>Rot45_Y</th>\n",
       "      <th>Rot60_X</th>\n",
       "      <th>Rot60_Y</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.780490e+05</td>\n",
       "      <td>8.780490e+05</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>8.780490e+05</td>\n",
       "      <td>8.780490e+05</td>\n",
       "      <td>8.780490e+05</td>\n",
       "      <td>8.780490e+05</td>\n",
       "      <td>8.780490e+05</td>\n",
       "      <td>8.780490e+05</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.735019e-13</td>\n",
       "      <td>3.121001e-13</td>\n",
       "      <td>20.155026</td>\n",
       "      <td>13.412655</td>\n",
       "      <td>15.570623</td>\n",
       "      <td>6.436509</td>\n",
       "      <td>2008.712046</td>\n",
       "      <td>12.185458</td>\n",
       "      <td>7.743576</td>\n",
       "      <td>3.406185e-13</td>\n",
       "      <td>5.570307e-13</td>\n",
       "      <td>1.848454e-13</td>\n",
       "      <td>6.262101e-13</td>\n",
       "      <td>1.647390e-14</td>\n",
       "      <td>6.527094e-13</td>\n",
       "      <td>1.219242</td>\n",
       "      <td>0.278861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>18.594915</td>\n",
       "      <td>6.549573</td>\n",
       "      <td>8.783005</td>\n",
       "      <td>3.428972</td>\n",
       "      <td>3.631194</td>\n",
       "      <td>7.482940</td>\n",
       "      <td>10.233725</td>\n",
       "      <td>9.308645e-01</td>\n",
       "      <td>1.064657e+00</td>\n",
       "      <td>9.197051e-01</td>\n",
       "      <td>1.074311e+00</td>\n",
       "      <td>9.308645e-01</td>\n",
       "      <td>1.064657e+00</td>\n",
       "      <td>0.716553</td>\n",
       "      <td>1.652405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.131839e+00</td>\n",
       "      <td>-5.793824e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.416996e+00</td>\n",
       "      <td>-5.778366e+00</td>\n",
       "      <td>-5.004354e+00</td>\n",
       "      <td>-5.856123e+00</td>\n",
       "      <td>-4.250673e+00</td>\n",
       "      <td>-5.578530e+00</td>\n",
       "      <td>0.020040</td>\n",
       "      <td>-3.141537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.028241e-01</td>\n",
       "      <td>-6.042785e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.145686e-01</td>\n",
       "      <td>-5.663677e-01</td>\n",
       "      <td>-4.910436e-01</td>\n",
       "      <td>-5.401645e-01</td>\n",
       "      <td>-5.844075e-01</td>\n",
       "      <td>-4.588684e-01</td>\n",
       "      <td>0.742397</td>\n",
       "      <td>-1.065725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.508183e-01</td>\n",
       "      <td>3.470628e-01</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.283380e-02</td>\n",
       "      <td>2.143151e-01</td>\n",
       "      <td>-9.704313e-02</td>\n",
       "      <td>2.239820e-01</td>\n",
       "      <td>-2.373112e-01</td>\n",
       "      <td>3.124186e-01</td>\n",
       "      <td>1.003652</td>\n",
       "      <td>0.508752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.250170e-01</td>\n",
       "      <td>7.172416e-01</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.804098e-01</td>\n",
       "      <td>8.071335e-01</td>\n",
       "      <td>4.085005e-01</td>\n",
       "      <td>7.867346e-01</td>\n",
       "      <td>5.062488e-01</td>\n",
       "      <td>7.511797e-01</td>\n",
       "      <td>1.639584</td>\n",
       "      <td>1.172370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.457357e+00</td>\n",
       "      <td>3.178581e+00</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>6.679617e+00</td>\n",
       "      <td>3.266535e+00</td>\n",
       "      <td>7.139107e+00</td>\n",
       "      <td>3.540117e+00</td>\n",
       "      <td>7.112078e+00</td>\n",
       "      <td>3.572446e+00</td>\n",
       "      <td>7.187824</td>\n",
       "      <td>3.141194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  X             Y         Minute           Hour  \\\n",
       "count  8.780490e+05  8.780490e+05  878049.000000  878049.000000   \n",
       "mean   5.735019e-13  3.121001e-13      20.155026      13.412655   \n",
       "std    1.000001e+00  1.000001e+00      18.594915       6.549573   \n",
       "min   -5.131839e+00 -5.793824e+00       0.000000       0.000000   \n",
       "25%   -4.028241e-01 -6.042785e-01       0.000000       9.000000   \n",
       "50%    2.508183e-01  3.470628e-01      19.000000      14.000000   \n",
       "75%    6.250170e-01  7.172416e-01      33.000000      19.000000   \n",
       "max    4.457357e+00  3.178581e+00      59.000000      23.000000   \n",
       "\n",
       "                 Day          Month           Year     WeekOfYear  \\\n",
       "count  878049.000000  878049.000000  878049.000000  878049.000000   \n",
       "mean       15.570623       6.436509    2008.712046      12.185458   \n",
       "std         8.783005       3.428972       3.631194       7.482940   \n",
       "min         1.000000       1.000000    2003.000000       0.000000   \n",
       "25%         8.000000       3.000000    2006.000000       6.000000   \n",
       "50%        16.000000       6.000000    2009.000000      12.000000   \n",
       "75%        23.000000       9.000000    2012.000000      19.000000   \n",
       "max        31.000000      12.000000    2015.000000      25.000000   \n",
       "\n",
       "             BlockNo       Rot30_X       Rot30_Y       Rot45_X       Rot45_Y  \\\n",
       "count  878049.000000  8.780490e+05  8.780490e+05  8.780490e+05  8.780490e+05   \n",
       "mean        7.743576  3.406185e-13  5.570307e-13  1.848454e-13  6.262101e-13   \n",
       "std        10.233725  9.308645e-01  1.064657e+00  9.197051e-01  1.074311e+00   \n",
       "min         0.000000 -5.416996e+00 -5.778366e+00 -5.004354e+00 -5.856123e+00   \n",
       "25%         0.000000 -4.145686e-01 -5.663677e-01 -4.910436e-01 -5.401645e-01   \n",
       "50%         4.000000  6.283380e-02  2.143151e-01 -9.704313e-02  2.239820e-01   \n",
       "75%        11.000000  4.804098e-01  8.071335e-01  4.085005e-01  7.867346e-01   \n",
       "max        84.000000  6.679617e+00  3.266535e+00  7.139107e+00  3.540117e+00   \n",
       "\n",
       "            Rot60_X       Rot60_Y         Radius          Angle  \n",
       "count  8.780490e+05  8.780490e+05  878049.000000  878049.000000  \n",
       "mean   1.647390e-14  6.527094e-13       1.219242       0.278861  \n",
       "std    9.308645e-01  1.064657e+00       0.716553       1.652405  \n",
       "min   -4.250673e+00 -5.578530e+00       0.020040      -3.141537  \n",
       "25%   -5.844075e-01 -4.588684e-01       0.742397      -1.065725  \n",
       "50%   -2.373112e-01  3.124186e-01       1.003652       0.508752  \n",
       "75%    5.062488e-01  7.511797e-01       1.639584       1.172370  \n",
       "max    7.112078e+00  3.572446e+00       7.187824       3.141194  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the description of the numerical features again to ensure everything is right\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:25.723811Z",
     "start_time": "2018-09-15T00:11:25.127445Z"
    }
   },
   "outputs": [],
   "source": [
    "# run KMeans separately on both the training set and test set\n",
    "data = [train_df, test_df]\n",
    "num_clusters = 40\n",
    "for dataset in data:\n",
    "    coordinates = dataset.loc[:,['Y','X']]\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=1).fit(coordinates)\n",
    "    id_labels=kmeans.labels_\n",
    "#     print(kmeans.cluster_centers_)\n",
    "    dataset['Cluster'] = id_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:25.757165Z",
     "start_time": "2018-09-15T00:15:25.727020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Minute</th>\n",
       "      <th>...</th>\n",
       "      <th>BlockNo</th>\n",
       "      <th>Rot30_X</th>\n",
       "      <th>Rot30_Y</th>\n",
       "      <th>Rot45_X</th>\n",
       "      <th>Rot45_Y</th>\n",
       "      <th>Rot60_X</th>\n",
       "      <th>Rot60_Y</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Angle</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>WARRANT ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-0.123653</td>\n",
       "      <td>0.313048</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.263611</td>\n",
       "      <td>0.209281</td>\n",
       "      <td>-0.308794</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>-0.332934</td>\n",
       "      <td>0.049437</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>-0.376186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-0.123653</td>\n",
       "      <td>0.313048</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.263611</td>\n",
       "      <td>0.209281</td>\n",
       "      <td>-0.308794</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>-0.332934</td>\n",
       "      <td>0.049437</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>-0.376186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-13 23:33:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>VANNESS AV / GREENWICH ST</td>\n",
       "      <td>-0.063205</td>\n",
       "      <td>1.381165</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.745320</td>\n",
       "      <td>1.164521</td>\n",
       "      <td>-1.021324</td>\n",
       "      <td>0.931938</td>\n",
       "      <td>-1.227727</td>\n",
       "      <td>0.635845</td>\n",
       "      <td>1.382611</td>\n",
       "      <td>-0.045730</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1500 Block of LOMBARD ST</td>\n",
       "      <td>-0.167295</td>\n",
       "      <td>1.400128</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.844945</td>\n",
       "      <td>1.128899</td>\n",
       "      <td>-1.108335</td>\n",
       "      <td>0.871744</td>\n",
       "      <td>-1.296194</td>\n",
       "      <td>0.555182</td>\n",
       "      <td>1.410087</td>\n",
       "      <td>-0.118922</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>PARK</td>\n",
       "      <td>NONE</td>\n",
       "      <td>100 Block of BRODERICK ST</td>\n",
       "      <td>-0.631622</td>\n",
       "      <td>0.186548</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.640275</td>\n",
       "      <td>-0.154255</td>\n",
       "      <td>-0.578534</td>\n",
       "      <td>-0.314714</td>\n",
       "      <td>-0.477366</td>\n",
       "      <td>-0.453726</td>\n",
       "      <td>0.658594</td>\n",
       "      <td>-1.283613</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dates        Category                      Descript  \\\n",
       "0 2015-05-13 23:53:00        WARRANTS                WARRANT ARREST   \n",
       "1 2015-05-13 23:53:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "2 2015-05-13 23:33:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "3 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "4 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "\n",
       "   DayOfWeek PdDistrict      Resolution                    Address         X  \\\n",
       "0  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST -0.123653   \n",
       "1  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST -0.123653   \n",
       "2  Wednesday   NORTHERN  ARREST, BOOKED  VANNESS AV / GREENWICH ST -0.063205   \n",
       "3  Wednesday   NORTHERN            NONE   1500 Block of LOMBARD ST -0.167295   \n",
       "4  Wednesday       PARK            NONE  100 Block of BRODERICK ST -0.631622   \n",
       "\n",
       "          Y  Minute  ...  BlockNo   Rot30_X   Rot30_Y   Rot45_X   Rot45_Y  \\\n",
       "0  0.313048      53  ...        0 -0.263611  0.209281 -0.308794  0.133923   \n",
       "1  0.313048      53  ...        0 -0.263611  0.209281 -0.308794  0.133923   \n",
       "2  1.381165      33  ...        0 -0.745320  1.164521 -1.021324  0.931938   \n",
       "3  1.400128      30  ...       16 -0.844945  1.128899 -1.108335  0.871744   \n",
       "4  0.186548      30  ...        2 -0.640275 -0.154255 -0.578534 -0.314714   \n",
       "\n",
       "    Rot60_X   Rot60_Y    Radius     Angle  Cluster  \n",
       "0 -0.332934  0.049437  0.336585 -0.376186        1  \n",
       "1 -0.332934  0.049437  0.336585 -0.376186        1  \n",
       "2 -1.227727  0.635845  1.382611 -0.045730       22  \n",
       "3 -1.296194  0.555182  1.410087 -0.118922       31  \n",
       "4 -0.477366 -0.453726  0.658594 -1.283613       27  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Features\n",
    "\n",
    "- We have already extracted all the necessary features from the `Address` attribute, so drop\n",
    "- We don't need `Resolution` or `Descript` features since it is not included in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop PdDistrict feature from both train and test set\n",
    "train_df.drop(['PdDistrict'], axis=1, inplace=True)\n",
    "test_df.drop(['PdDistrict'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:26.460052Z",
     "start_time": "2018-09-15T00:15:25.759851Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop Address feature from both train and test set\n",
    "train_df.drop(['Address'], axis=1, inplace=True)\n",
    "test_df.drop(['Address'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:26.724329Z",
     "start_time": "2018-09-15T00:15:26.462106Z"
    }
   },
   "outputs": [],
   "source": [
    "# We don't need Dates column anymore\n",
    "train_df.drop(['Dates'], axis=1, inplace=True)\n",
    "test_df.drop(['Dates'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:26.815822Z",
     "start_time": "2018-09-15T00:15:26.726626Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop Resolution column since test set does not have this column\n",
    "train_df.drop(['Resolution'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:26.912963Z",
     "start_time": "2018-09-15T00:15:26.817639Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop Descript column since test set does not have this column\n",
    "train_df.drop(['Descript'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:26.936327Z",
     "start_time": "2018-09-15T00:15:26.915051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>WeekOfYear</th>\n",
       "      <th>...</th>\n",
       "      <th>BlockNo</th>\n",
       "      <th>Rot30_X</th>\n",
       "      <th>Rot30_Y</th>\n",
       "      <th>Rot45_X</th>\n",
       "      <th>Rot45_Y</th>\n",
       "      <th>Rot60_X</th>\n",
       "      <th>Rot60_Y</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Angle</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>-0.123653</td>\n",
       "      <td>0.313048</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.263611</td>\n",
       "      <td>0.209281</td>\n",
       "      <td>-0.308794</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>-0.332934</td>\n",
       "      <td>0.049437</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>-0.376186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>-0.123653</td>\n",
       "      <td>0.313048</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.263611</td>\n",
       "      <td>0.209281</td>\n",
       "      <td>-0.308794</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>-0.332934</td>\n",
       "      <td>0.049437</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>-0.376186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>-0.063205</td>\n",
       "      <td>1.381165</td>\n",
       "      <td>33</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.745320</td>\n",
       "      <td>1.164521</td>\n",
       "      <td>-1.021324</td>\n",
       "      <td>0.931938</td>\n",
       "      <td>-1.227727</td>\n",
       "      <td>0.635845</td>\n",
       "      <td>1.382611</td>\n",
       "      <td>-0.045730</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>-0.167295</td>\n",
       "      <td>1.400128</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.844945</td>\n",
       "      <td>1.128899</td>\n",
       "      <td>-1.108335</td>\n",
       "      <td>0.871744</td>\n",
       "      <td>-1.296194</td>\n",
       "      <td>0.555182</td>\n",
       "      <td>1.410087</td>\n",
       "      <td>-0.118922</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>-0.631622</td>\n",
       "      <td>0.186548</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.640275</td>\n",
       "      <td>-0.154255</td>\n",
       "      <td>-0.578534</td>\n",
       "      <td>-0.314714</td>\n",
       "      <td>-0.477366</td>\n",
       "      <td>-0.453726</td>\n",
       "      <td>0.658594</td>\n",
       "      <td>-1.283613</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Category  DayOfWeek         X         Y  Minute  Hour  Day  Month  \\\n",
       "0        WARRANTS  Wednesday -0.123653  0.313048      53    23   13      5   \n",
       "1  OTHER OFFENSES  Wednesday -0.123653  0.313048      53    23   13      5   \n",
       "2  OTHER OFFENSES  Wednesday -0.063205  1.381165      33    23   13      5   \n",
       "3   LARCENY/THEFT  Wednesday -0.167295  1.400128      30    23   13      5   \n",
       "4   LARCENY/THEFT  Wednesday -0.631622  0.186548      30    23   13      5   \n",
       "\n",
       "   Year  WeekOfYear  ... BlockNo   Rot30_X   Rot30_Y   Rot45_X   Rot45_Y  \\\n",
       "0  2015           9  ...       0 -0.263611  0.209281 -0.308794  0.133923   \n",
       "1  2015           9  ...       0 -0.263611  0.209281 -0.308794  0.133923   \n",
       "2  2015           9  ...       0 -0.745320  1.164521 -1.021324  0.931938   \n",
       "3  2015           9  ...      16 -0.844945  1.128899 -1.108335  0.871744   \n",
       "4  2015           9  ...       2 -0.640275 -0.154255 -0.578534 -0.314714   \n",
       "\n",
       "    Rot60_X   Rot60_Y    Radius     Angle  Cluster  \n",
       "0 -0.332934  0.049437  0.336585 -0.376186        1  \n",
       "1 -0.332934  0.049437  0.336585 -0.376186        1  \n",
       "2 -1.227727  0.635845  1.382611 -0.045730       22  \n",
       "3 -1.296194  0.555182  1.410087 -0.118922       31  \n",
       "4 -0.477366 -0.453726  0.658594 -1.283613       27  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's quickly view the data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Encoding \n",
    "\n",
    "- Convert categorical data to numeric data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pd Districts\n",
    "\n",
    "- convert Pd District categorical feature to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:27.960027Z",
     "start_time": "2018-09-15T00:15:26.938164Z"
    }
   },
   "outputs": [],
   "source": [
    "# pd_districts = {'SOUTHERN':0, 'MISSION':1, 'NORTHERN':2, 'CENTRAL':3, 'BAYVIEW':4, 'INGLESIDE':5, \n",
    "#                 'TENDERLOIN':6, 'TARAVAL':7, 'PARK':8, 'RICHMOND':9}\n",
    "\n",
    "# train_df['PdDistrict'].replace(pd_districts, inplace=True)\n",
    "# test_df['PdDistrict'].replace(pd_districts, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:27.981326Z",
     "start_time": "2018-09-15T00:15:27.961850Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:28.480435Z",
     "start_time": "2018-09-15T00:15:27.983129Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Year\n",
    "\n",
    "- Year is an **ordinal** variable, so let's keep that ordering and mapping\n",
    "- convert Year categorical feature to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:28.548217Z",
     "start_time": "2018-09-15T00:15:28.482183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015]\n",
      "[2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015]\n"
     ]
    }
   ],
   "source": [
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    year_le = LabelEncoder()\n",
    "    year_le.fit(dataset['Year'].unique())\n",
    "    print(list(year_le.classes_))\n",
    "\n",
    "    dataset['Year']=year_le.transform(dataset['Year']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:28.558184Z",
     "start_time": "2018-09-15T00:15:28.549815Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1,  0])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:28.565007Z",
     "start_time": "2018-09-15T00:15:28.560030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2003: 0,\n",
       " 2004: 1,\n",
       " 2005: 2,\n",
       " 2006: 3,\n",
       " 2007: 4,\n",
       " 2008: 5,\n",
       " 2009: 6,\n",
       " 2010: 7,\n",
       " 2011: 8,\n",
       " 2012: 9,\n",
       " 2013: 10,\n",
       " 2014: 11,\n",
       " 2015: 12}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So we know the mapping (important)\n",
    "dict(zip(year_le.classes_, year_le.transform(year_le.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:28.586908Z",
     "start_time": "2018-09-15T00:15:28.566585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>WeekOfYear</th>\n",
       "      <th>...</th>\n",
       "      <th>BlockNo</th>\n",
       "      <th>Rot30_X</th>\n",
       "      <th>Rot30_Y</th>\n",
       "      <th>Rot45_X</th>\n",
       "      <th>Rot45_Y</th>\n",
       "      <th>Rot60_X</th>\n",
       "      <th>Rot60_Y</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Angle</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>-0.123653</td>\n",
       "      <td>0.313048</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.263611</td>\n",
       "      <td>0.209281</td>\n",
       "      <td>-0.308794</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>-0.332934</td>\n",
       "      <td>0.049437</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>-0.376186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>-0.123653</td>\n",
       "      <td>0.313048</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.263611</td>\n",
       "      <td>0.209281</td>\n",
       "      <td>-0.308794</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>-0.332934</td>\n",
       "      <td>0.049437</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>-0.376186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>-0.063205</td>\n",
       "      <td>1.381165</td>\n",
       "      <td>33</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.745320</td>\n",
       "      <td>1.164521</td>\n",
       "      <td>-1.021324</td>\n",
       "      <td>0.931938</td>\n",
       "      <td>-1.227727</td>\n",
       "      <td>0.635845</td>\n",
       "      <td>1.382611</td>\n",
       "      <td>-0.045730</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>-0.167295</td>\n",
       "      <td>1.400128</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.844945</td>\n",
       "      <td>1.128899</td>\n",
       "      <td>-1.108335</td>\n",
       "      <td>0.871744</td>\n",
       "      <td>-1.296194</td>\n",
       "      <td>0.555182</td>\n",
       "      <td>1.410087</td>\n",
       "      <td>-0.118922</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>-0.631622</td>\n",
       "      <td>0.186548</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.640275</td>\n",
       "      <td>-0.154255</td>\n",
       "      <td>-0.578534</td>\n",
       "      <td>-0.314714</td>\n",
       "      <td>-0.477366</td>\n",
       "      <td>-0.453726</td>\n",
       "      <td>0.658594</td>\n",
       "      <td>-1.283613</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Category  DayOfWeek         X         Y  Minute  Hour  Day  Month  \\\n",
       "0        WARRANTS  Wednesday -0.123653  0.313048      53    23   13      5   \n",
       "1  OTHER OFFENSES  Wednesday -0.123653  0.313048      53    23   13      5   \n",
       "2  OTHER OFFENSES  Wednesday -0.063205  1.381165      33    23   13      5   \n",
       "3   LARCENY/THEFT  Wednesday -0.167295  1.400128      30    23   13      5   \n",
       "4   LARCENY/THEFT  Wednesday -0.631622  0.186548      30    23   13      5   \n",
       "\n",
       "   Year  WeekOfYear  ... BlockNo   Rot30_X   Rot30_Y   Rot45_X   Rot45_Y  \\\n",
       "0    12           9  ...       0 -0.263611  0.209281 -0.308794  0.133923   \n",
       "1    12           9  ...       0 -0.263611  0.209281 -0.308794  0.133923   \n",
       "2    12           9  ...       0 -0.745320  1.164521 -1.021324  0.931938   \n",
       "3    12           9  ...      16 -0.844945  1.128899 -1.108335  0.871744   \n",
       "4    12           9  ...       2 -0.640275 -0.154255 -0.578534 -0.314714   \n",
       "\n",
       "    Rot60_X   Rot60_Y    Radius     Angle  Cluster  \n",
       "0 -0.332934  0.049437  0.336585 -0.376186        1  \n",
       "1 -0.332934  0.049437  0.336585 -0.376186        1  \n",
       "2 -1.227727  0.635845  1.382611 -0.045730       22  \n",
       "3 -1.296194  0.555182  1.410087 -0.118922       31  \n",
       "4 -0.477366 -0.453726  0.658594 -1.283613       27  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:28.960961Z",
     "start_time": "2018-09-15T00:15:28.588787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 878049 entries, 0 to 878048\n",
      "Data columns (total 21 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   Category    878049 non-null  object \n",
      " 1   DayOfWeek   878049 non-null  object \n",
      " 2   X           878049 non-null  float64\n",
      " 3   Y           878049 non-null  float64\n",
      " 4   Minute      878049 non-null  int64  \n",
      " 5   Hour        878049 non-null  int64  \n",
      " 6   Day         878049 non-null  int64  \n",
      " 7   Month       878049 non-null  int64  \n",
      " 8   Year        878049 non-null  int64  \n",
      " 9   WeekOfYear  878049 non-null  int64  \n",
      " 10  StreetType  878049 non-null  object \n",
      " 11  BlockNo     878049 non-null  int64  \n",
      " 12  Rot30_X     878049 non-null  float64\n",
      " 13  Rot30_Y     878049 non-null  float64\n",
      " 14  Rot45_X     878049 non-null  float64\n",
      " 15  Rot45_Y     878049 non-null  float64\n",
      " 16  Rot60_X     878049 non-null  float64\n",
      " 17  Rot60_Y     878049 non-null  float64\n",
      " 18  Radius      878049 non-null  float64\n",
      " 19  Angle       878049 non-null  float64\n",
      " 20  Cluster     878049 non-null  int32  \n",
      "dtypes: float64(10), int32(1), int64(7), object(3)\n",
      "memory usage: 137.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DayOfWeek\n",
    "\n",
    "- we are going to use sklearn's LabelEncoder to encode the categorical data to numeric\n",
    "- Day of week is considered a categorical and nominal variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:30.490086Z",
     "start_time": "2018-09-15T00:15:28.963333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday']\n",
      "['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday']\n"
     ]
    }
   ],
   "source": [
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dow_le = LabelEncoder()\n",
    "    dow_le.fit(dataset['DayOfWeek'].unique())\n",
    "    print(list(dow_le.classes_))\n",
    "    dataset['DayOfWeek']=dow_le.transform(dataset['DayOfWeek'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:30.502616Z",
     "start_time": "2018-09-15T00:15:30.491985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 5, 1, 3, 2, 0, 4])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['DayOfWeek'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:30.514008Z",
     "start_time": "2018-09-15T00:15:30.505862Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Friday': 0,\n",
       " 'Monday': 1,\n",
       " 'Saturday': 2,\n",
       " 'Sunday': 3,\n",
       " 'Thursday': 4,\n",
       " 'Tuesday': 5,\n",
       " 'Wednesday': 6}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So we know the mapping (important)\n",
    "dict(zip(dow_le.classes_, dow_le.transform(dow_le.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:30.541416Z",
     "start_time": "2018-09-15T00:15:30.517311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>WeekOfYear</th>\n",
       "      <th>...</th>\n",
       "      <th>BlockNo</th>\n",
       "      <th>Rot30_X</th>\n",
       "      <th>Rot30_Y</th>\n",
       "      <th>Rot45_X</th>\n",
       "      <th>Rot45_Y</th>\n",
       "      <th>Rot60_X</th>\n",
       "      <th>Rot60_Y</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Angle</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.123653</td>\n",
       "      <td>0.313048</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.263611</td>\n",
       "      <td>0.209281</td>\n",
       "      <td>-0.308794</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>-0.332934</td>\n",
       "      <td>0.049437</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>-0.376186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.123653</td>\n",
       "      <td>0.313048</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.263611</td>\n",
       "      <td>0.209281</td>\n",
       "      <td>-0.308794</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>-0.332934</td>\n",
       "      <td>0.049437</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>-0.376186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.063205</td>\n",
       "      <td>1.381165</td>\n",
       "      <td>33</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.745320</td>\n",
       "      <td>1.164521</td>\n",
       "      <td>-1.021324</td>\n",
       "      <td>0.931938</td>\n",
       "      <td>-1.227727</td>\n",
       "      <td>0.635845</td>\n",
       "      <td>1.382611</td>\n",
       "      <td>-0.045730</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.167295</td>\n",
       "      <td>1.400128</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.844945</td>\n",
       "      <td>1.128899</td>\n",
       "      <td>-1.108335</td>\n",
       "      <td>0.871744</td>\n",
       "      <td>-1.296194</td>\n",
       "      <td>0.555182</td>\n",
       "      <td>1.410087</td>\n",
       "      <td>-0.118922</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.631622</td>\n",
       "      <td>0.186548</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.640275</td>\n",
       "      <td>-0.154255</td>\n",
       "      <td>-0.578534</td>\n",
       "      <td>-0.314714</td>\n",
       "      <td>-0.477366</td>\n",
       "      <td>-0.453726</td>\n",
       "      <td>0.658594</td>\n",
       "      <td>-1.283613</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Category  DayOfWeek         X         Y  Minute  Hour  Day  Month  \\\n",
       "0        WARRANTS          6 -0.123653  0.313048      53    23   13      5   \n",
       "1  OTHER OFFENSES          6 -0.123653  0.313048      53    23   13      5   \n",
       "2  OTHER OFFENSES          6 -0.063205  1.381165      33    23   13      5   \n",
       "3   LARCENY/THEFT          6 -0.167295  1.400128      30    23   13      5   \n",
       "4   LARCENY/THEFT          6 -0.631622  0.186548      30    23   13      5   \n",
       "\n",
       "   Year  WeekOfYear  ... BlockNo   Rot30_X   Rot30_Y   Rot45_X   Rot45_Y  \\\n",
       "0    12           9  ...       0 -0.263611  0.209281 -0.308794  0.133923   \n",
       "1    12           9  ...       0 -0.263611  0.209281 -0.308794  0.133923   \n",
       "2    12           9  ...       0 -0.745320  1.164521 -1.021324  0.931938   \n",
       "3    12           9  ...      16 -0.844945  1.128899 -1.108335  0.871744   \n",
       "4    12           9  ...       2 -0.640275 -0.154255 -0.578534 -0.314714   \n",
       "\n",
       "    Rot60_X   Rot60_Y    Radius     Angle  Cluster  \n",
       "0 -0.332934  0.049437  0.336585 -0.376186        1  \n",
       "1 -0.332934  0.049437  0.336585 -0.376186        1  \n",
       "2 -1.227727  0.635845  1.382611 -0.045730       22  \n",
       "3 -1.296194  0.555182  1.410087 -0.118922       31  \n",
       "4 -0.477366 -0.453726  0.658594 -1.283613       27  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:31.019915Z",
     "start_time": "2018-09-15T00:15:30.543207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 878049 entries, 0 to 878048\n",
      "Data columns (total 21 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   Category    878049 non-null  object \n",
      " 1   DayOfWeek   878049 non-null  int64  \n",
      " 2   X           878049 non-null  float64\n",
      " 3   Y           878049 non-null  float64\n",
      " 4   Minute      878049 non-null  int64  \n",
      " 5   Hour        878049 non-null  int64  \n",
      " 6   Day         878049 non-null  int64  \n",
      " 7   Month       878049 non-null  int64  \n",
      " 8   Year        878049 non-null  int64  \n",
      " 9   WeekOfYear  878049 non-null  int64  \n",
      " 10  StreetType  878049 non-null  object \n",
      " 11  BlockNo     878049 non-null  int64  \n",
      " 12  Rot30_X     878049 non-null  float64\n",
      " 13  Rot30_Y     878049 non-null  float64\n",
      " 14  Rot45_X     878049 non-null  float64\n",
      " 15  Rot45_Y     878049 non-null  float64\n",
      " 16  Rot60_X     878049 non-null  float64\n",
      " 17  Rot60_Y     878049 non-null  float64\n",
      " 18  Radius      878049 non-null  float64\n",
      " 19  Angle       878049 non-null  float64\n",
      " 20  Cluster     878049 non-null  int32  \n",
      "dtypes: float64(10), int32(1), int64(8), object(2)\n",
      "memory usage: 137.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Street Type\n",
    "\n",
    "- we are going to use sklearn's LabelEncoder to encode the categorical data to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:32.609940Z",
     "start_time": "2018-09-15T00:15:31.021643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AL', 'AV', 'BL', 'CR', 'CT', 'DR', 'EL CAMINO DEL MAR', 'HY', 'I-80', 'INT', 'LN', 'OTHER', 'PL', 'PZ', 'RD', 'RW', 'ST', 'TR', 'WAY', 'WK', 'WY']\n",
      "['AL', 'AV', 'BL', 'CR', 'CT', 'DR', 'EL CAMINO DEL MAR', 'HY', 'I-80', 'INT', 'LN', 'OTHER', 'PL', 'PZ', 'RD', 'RW', 'ST', 'TR', 'WAY', 'WK', 'WY']\n"
     ]
    }
   ],
   "source": [
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    st_le = LabelEncoder()\n",
    "    st_le.fit(dataset['StreetType'].unique())\n",
    "    print(list(st_le.classes_))\n",
    "    dataset['StreetType']=st_le.transform(dataset['StreetType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:32.621448Z",
     "start_time": "2018-09-15T00:15:32.611850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 16,  1, 20,  4,  5, 17,  7, 14, 13,  2, 12, 10, 18,  3,  0, 11,\n",
       "       19, 15,  6,  8])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['StreetType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:32.656477Z",
     "start_time": "2018-09-15T00:15:32.631106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>WeekOfYear</th>\n",
       "      <th>...</th>\n",
       "      <th>BlockNo</th>\n",
       "      <th>Rot30_X</th>\n",
       "      <th>Rot30_Y</th>\n",
       "      <th>Rot45_X</th>\n",
       "      <th>Rot45_Y</th>\n",
       "      <th>Rot60_X</th>\n",
       "      <th>Rot60_Y</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Angle</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.123653</td>\n",
       "      <td>0.313048</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.263611</td>\n",
       "      <td>0.209281</td>\n",
       "      <td>-0.308794</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>-0.332934</td>\n",
       "      <td>0.049437</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>-0.376186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.123653</td>\n",
       "      <td>0.313048</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.263611</td>\n",
       "      <td>0.209281</td>\n",
       "      <td>-0.308794</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>-0.332934</td>\n",
       "      <td>0.049437</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>-0.376186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.063205</td>\n",
       "      <td>1.381165</td>\n",
       "      <td>33</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.745320</td>\n",
       "      <td>1.164521</td>\n",
       "      <td>-1.021324</td>\n",
       "      <td>0.931938</td>\n",
       "      <td>-1.227727</td>\n",
       "      <td>0.635845</td>\n",
       "      <td>1.382611</td>\n",
       "      <td>-0.045730</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.167295</td>\n",
       "      <td>1.400128</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.844945</td>\n",
       "      <td>1.128899</td>\n",
       "      <td>-1.108335</td>\n",
       "      <td>0.871744</td>\n",
       "      <td>-1.296194</td>\n",
       "      <td>0.555182</td>\n",
       "      <td>1.410087</td>\n",
       "      <td>-0.118922</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.631622</td>\n",
       "      <td>0.186548</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.640275</td>\n",
       "      <td>-0.154255</td>\n",
       "      <td>-0.578534</td>\n",
       "      <td>-0.314714</td>\n",
       "      <td>-0.477366</td>\n",
       "      <td>-0.453726</td>\n",
       "      <td>0.658594</td>\n",
       "      <td>-1.283613</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Category  DayOfWeek         X         Y  Minute  Hour  Day  Month  \\\n",
       "0        WARRANTS          6 -0.123653  0.313048      53    23   13      5   \n",
       "1  OTHER OFFENSES          6 -0.123653  0.313048      53    23   13      5   \n",
       "2  OTHER OFFENSES          6 -0.063205  1.381165      33    23   13      5   \n",
       "3   LARCENY/THEFT          6 -0.167295  1.400128      30    23   13      5   \n",
       "4   LARCENY/THEFT          6 -0.631622  0.186548      30    23   13      5   \n",
       "\n",
       "   Year  WeekOfYear  ...  BlockNo   Rot30_X   Rot30_Y   Rot45_X   Rot45_Y  \\\n",
       "0    12           9  ...        0 -0.263611  0.209281 -0.308794  0.133923   \n",
       "1    12           9  ...        0 -0.263611  0.209281 -0.308794  0.133923   \n",
       "2    12           9  ...        0 -0.745320  1.164521 -1.021324  0.931938   \n",
       "3    12           9  ...       16 -0.844945  1.128899 -1.108335  0.871744   \n",
       "4    12           9  ...        2 -0.640275 -0.154255 -0.578534 -0.314714   \n",
       "\n",
       "    Rot60_X   Rot60_Y    Radius     Angle  Cluster  \n",
       "0 -0.332934  0.049437  0.336585 -0.376186        1  \n",
       "1 -0.332934  0.049437  0.336585 -0.376186        1  \n",
       "2 -1.227727  0.635845  1.382611 -0.045730       22  \n",
       "3 -1.296194  0.555182  1.410087 -0.118922       31  \n",
       "4 -0.477366 -0.453726  0.658594 -1.283613       27  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:33.124717Z",
     "start_time": "2018-09-15T00:15:32.658114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 878049 entries, 0 to 878048\n",
      "Data columns (total 21 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   Category    878049 non-null  object \n",
      " 1   DayOfWeek   878049 non-null  int64  \n",
      " 2   X           878049 non-null  float64\n",
      " 3   Y           878049 non-null  float64\n",
      " 4   Minute      878049 non-null  int64  \n",
      " 5   Hour        878049 non-null  int64  \n",
      " 6   Day         878049 non-null  int64  \n",
      " 7   Month       878049 non-null  int64  \n",
      " 8   Year        878049 non-null  int64  \n",
      " 9   WeekOfYear  878049 non-null  int64  \n",
      " 10  StreetType  878049 non-null  int64  \n",
      " 11  BlockNo     878049 non-null  int64  \n",
      " 12  Rot30_X     878049 non-null  float64\n",
      " 13  Rot30_Y     878049 non-null  float64\n",
      " 14  Rot45_X     878049 non-null  float64\n",
      " 15  Rot45_Y     878049 non-null  float64\n",
      " 16  Rot60_X     878049 non-null  float64\n",
      " 17  Rot60_Y     878049 non-null  float64\n",
      " 18  Radius      878049 non-null  float64\n",
      " 19  Angle       878049 non-null  float64\n",
      " 20  Cluster     878049 non-null  int32  \n",
      "dtypes: float64(10), int32(1), int64(9), object(1)\n",
      "memory usage: 137.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holiday\n",
    "\n",
    "- Encode the binary feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:33.366955Z",
     "start_time": "2018-09-15T00:15:33.126363Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Encode to 0 and 1\n",
    "\n",
    "# train_df['Holiday'].replace(False, 0, inplace=True)\n",
    "# train_df['Holiday'].replace(True, 1, inplace=True)\n",
    "# test_df['Holiday'].replace(False, 0, inplace=True)\n",
    "# test_df['Holiday'].replace(True, 1, inplace=True)\n",
    "\n",
    "# train_df['Holiday'] = train_df['Holiday'].astype('uint8')\n",
    "# train_df['Holiday'] = train_df['Holiday'].astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:33.401544Z",
     "start_time": "2018-09-15T00:15:33.368756Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_df[train_df['Holiday'] == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:33.644042Z",
     "start_time": "2018-09-15T00:15:33.403046Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_df[test_df['Holiday'] == 1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category\n",
    "\n",
    "- we are going to use sklearn's LabelEncoder to encode the categorical data to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:34.733063Z",
     "start_time": "2018-09-15T00:15:33.645874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARSON', 'ASSAULT', 'BAD CHECKS', 'BRIBERY', 'BURGLARY', 'DISORDERLY CONDUCT', 'DRIVING UNDER THE INFLUENCE', 'DRUG/NARCOTIC', 'DRUNKENNESS', 'EMBEZZLEMENT', 'EXTORTION', 'FAMILY OFFENSES', 'FORGERY/COUNTERFEITING', 'FRAUD', 'GAMBLING', 'KIDNAPPING', 'LARCENY/THEFT', 'LIQUOR LAWS', 'LOITERING', 'MISSING PERSON', 'NON-CRIMINAL', 'OTHER OFFENSES', 'PORNOGRAPHY/OBSCENE MAT', 'PROSTITUTION', 'RECOVERED VEHICLE', 'ROBBERY', 'RUNAWAY', 'SECONDARY CODES', 'SEX OFFENSES FORCIBLE', 'SEX OFFENSES NON FORCIBLE', 'STOLEN PROPERTY', 'SUICIDE', 'SUSPICIOUS OCC', 'TREA', 'TRESPASS', 'VANDALISM', 'VEHICLE THEFT', 'WARRANTS', 'WEAPON LAWS']\n"
     ]
    }
   ],
   "source": [
    "data = [train_df]\n",
    "\n",
    "for dataset in data:\n",
    "    cat_le = LabelEncoder()\n",
    "    cat_le.fit(dataset['Category'].unique())\n",
    "    print(list(cat_le.classes_))\n",
    "    dataset['Category']=cat_le.transform(dataset['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:34.744138Z",
     "start_time": "2018-09-15T00:15:34.735515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df['Category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:34.751446Z",
     "start_time": "2018-09-15T00:15:34.746020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ARSON': 0,\n",
       " 'ASSAULT': 1,\n",
       " 'BAD CHECKS': 2,\n",
       " 'BRIBERY': 3,\n",
       " 'BURGLARY': 4,\n",
       " 'DISORDERLY CONDUCT': 5,\n",
       " 'DRIVING UNDER THE INFLUENCE': 6,\n",
       " 'DRUG/NARCOTIC': 7,\n",
       " 'DRUNKENNESS': 8,\n",
       " 'EMBEZZLEMENT': 9,\n",
       " 'EXTORTION': 10,\n",
       " 'FAMILY OFFENSES': 11,\n",
       " 'FORGERY/COUNTERFEITING': 12,\n",
       " 'FRAUD': 13,\n",
       " 'GAMBLING': 14,\n",
       " 'KIDNAPPING': 15,\n",
       " 'LARCENY/THEFT': 16,\n",
       " 'LIQUOR LAWS': 17,\n",
       " 'LOITERING': 18,\n",
       " 'MISSING PERSON': 19,\n",
       " 'NON-CRIMINAL': 20,\n",
       " 'OTHER OFFENSES': 21,\n",
       " 'PORNOGRAPHY/OBSCENE MAT': 22,\n",
       " 'PROSTITUTION': 23,\n",
       " 'RECOVERED VEHICLE': 24,\n",
       " 'ROBBERY': 25,\n",
       " 'RUNAWAY': 26,\n",
       " 'SECONDARY CODES': 27,\n",
       " 'SEX OFFENSES FORCIBLE': 28,\n",
       " 'SEX OFFENSES NON FORCIBLE': 29,\n",
       " 'STOLEN PROPERTY': 30,\n",
       " 'SUICIDE': 31,\n",
       " 'SUSPICIOUS OCC': 32,\n",
       " 'TREA': 33,\n",
       " 'TRESPASS': 34,\n",
       " 'VANDALISM': 35,\n",
       " 'VEHICLE THEFT': 36,\n",
       " 'WARRANTS': 37,\n",
       " 'WEAPON LAWS': 38}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So we know the mapping (important)\n",
    "dict(zip(cat_le.classes_, cat_le.transform(cat_le.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:34.771176Z",
     "start_time": "2018-09-15T00:15:34.753364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>WeekOfYear</th>\n",
       "      <th>...</th>\n",
       "      <th>BlockNo</th>\n",
       "      <th>Rot30_X</th>\n",
       "      <th>Rot30_Y</th>\n",
       "      <th>Rot45_X</th>\n",
       "      <th>Rot45_Y</th>\n",
       "      <th>Rot60_X</th>\n",
       "      <th>Rot60_Y</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Angle</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.123653</td>\n",
       "      <td>0.313048</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.263611</td>\n",
       "      <td>0.209281</td>\n",
       "      <td>-0.308794</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>-0.332934</td>\n",
       "      <td>0.049437</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>-0.376186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.123653</td>\n",
       "      <td>0.313048</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.263611</td>\n",
       "      <td>0.209281</td>\n",
       "      <td>-0.308794</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>-0.332934</td>\n",
       "      <td>0.049437</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>-0.376186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.063205</td>\n",
       "      <td>1.381165</td>\n",
       "      <td>33</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.745320</td>\n",
       "      <td>1.164521</td>\n",
       "      <td>-1.021324</td>\n",
       "      <td>0.931938</td>\n",
       "      <td>-1.227727</td>\n",
       "      <td>0.635845</td>\n",
       "      <td>1.382611</td>\n",
       "      <td>-0.045730</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.167295</td>\n",
       "      <td>1.400128</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.844945</td>\n",
       "      <td>1.128899</td>\n",
       "      <td>-1.108335</td>\n",
       "      <td>0.871744</td>\n",
       "      <td>-1.296194</td>\n",
       "      <td>0.555182</td>\n",
       "      <td>1.410087</td>\n",
       "      <td>-0.118922</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.631622</td>\n",
       "      <td>0.186548</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.640275</td>\n",
       "      <td>-0.154255</td>\n",
       "      <td>-0.578534</td>\n",
       "      <td>-0.314714</td>\n",
       "      <td>-0.477366</td>\n",
       "      <td>-0.453726</td>\n",
       "      <td>0.658594</td>\n",
       "      <td>-1.283613</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category  DayOfWeek         X         Y  Minute  Hour  Day  Month  Year  \\\n",
       "0        37          6 -0.123653  0.313048      53    23   13      5    12   \n",
       "1        21          6 -0.123653  0.313048      53    23   13      5    12   \n",
       "2        21          6 -0.063205  1.381165      33    23   13      5    12   \n",
       "3        16          6 -0.167295  1.400128      30    23   13      5    12   \n",
       "4        16          6 -0.631622  0.186548      30    23   13      5    12   \n",
       "\n",
       "   WeekOfYear  ...  BlockNo   Rot30_X   Rot30_Y   Rot45_X   Rot45_Y   Rot60_X  \\\n",
       "0           9  ...        0 -0.263611  0.209281 -0.308794  0.133923 -0.332934   \n",
       "1           9  ...        0 -0.263611  0.209281 -0.308794  0.133923 -0.332934   \n",
       "2           9  ...        0 -0.745320  1.164521 -1.021324  0.931938 -1.227727   \n",
       "3           9  ...       16 -0.844945  1.128899 -1.108335  0.871744 -1.296194   \n",
       "4           9  ...        2 -0.640275 -0.154255 -0.578534 -0.314714 -0.477366   \n",
       "\n",
       "    Rot60_Y    Radius     Angle  Cluster  \n",
       "0  0.049437  0.336585 -0.376186        1  \n",
       "1  0.049437  0.336585 -0.376186        1  \n",
       "2  0.635845  1.382611 -0.045730       22  \n",
       "3  0.555182  1.410087 -0.118922       31  \n",
       "4 -0.453726  0.658594 -1.283613       27  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:35.216673Z",
     "start_time": "2018-09-15T00:15:34.772873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 878049 entries, 0 to 878048\n",
      "Data columns (total 21 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   Category    878049 non-null  int64  \n",
      " 1   DayOfWeek   878049 non-null  int64  \n",
      " 2   X           878049 non-null  float64\n",
      " 3   Y           878049 non-null  float64\n",
      " 4   Minute      878049 non-null  int64  \n",
      " 5   Hour        878049 non-null  int64  \n",
      " 6   Day         878049 non-null  int64  \n",
      " 7   Month       878049 non-null  int64  \n",
      " 8   Year        878049 non-null  int64  \n",
      " 9   WeekOfYear  878049 non-null  int64  \n",
      " 10  StreetType  878049 non-null  int64  \n",
      " 11  BlockNo     878049 non-null  int64  \n",
      " 12  Rot30_X     878049 non-null  float64\n",
      " 13  Rot30_Y     878049 non-null  float64\n",
      " 14  Rot45_X     878049 non-null  float64\n",
      " 15  Rot45_Y     878049 non-null  float64\n",
      " 16  Rot60_X     878049 non-null  float64\n",
      " 17  Rot60_Y     878049 non-null  float64\n",
      " 18  Radius      878049 non-null  float64\n",
      " 19  Angle       878049 non-null  float64\n",
      " 20  Cluster     878049 non-null  int32  \n",
      "dtypes: float64(10), int32(1), int64(10)\n",
      "memory usage: 137.3 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Information about Data\n",
    "\n",
    "- One last check before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:35.519400Z",
     "start_time": "2018-09-15T00:15:35.218326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 878049 entries, 0 to 878048\n",
      "Data columns (total 21 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   Category    878049 non-null  int64  \n",
      " 1   DayOfWeek   878049 non-null  int64  \n",
      " 2   X           878049 non-null  float64\n",
      " 3   Y           878049 non-null  float64\n",
      " 4   Minute      878049 non-null  int64  \n",
      " 5   Hour        878049 non-null  int64  \n",
      " 6   Day         878049 non-null  int64  \n",
      " 7   Month       878049 non-null  int64  \n",
      " 8   Year        878049 non-null  int64  \n",
      " 9   WeekOfYear  878049 non-null  int64  \n",
      " 10  StreetType  878049 non-null  int64  \n",
      " 11  BlockNo     878049 non-null  int64  \n",
      " 12  Rot30_X     878049 non-null  float64\n",
      " 13  Rot30_Y     878049 non-null  float64\n",
      " 14  Rot45_X     878049 non-null  float64\n",
      " 15  Rot45_Y     878049 non-null  float64\n",
      " 16  Rot60_X     878049 non-null  float64\n",
      " 17  Rot60_Y     878049 non-null  float64\n",
      " 18  Radius      878049 non-null  float64\n",
      " 19  Angle       878049 non-null  float64\n",
      " 20  Cluster     878049 non-null  int32  \n",
      "dtypes: float64(10), int32(1), int64(10)\n",
      "memory usage: 137.3 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:36.424967Z",
     "start_time": "2018-09-15T00:15:35.520949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 878049 entries, 0 to 878048\n",
      "Data columns (total 21 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   Category    878049 non-null  int64  \n",
      " 1   DayOfWeek   878049 non-null  int16  \n",
      " 2   X           878049 non-null  float64\n",
      " 3   Y           878049 non-null  float64\n",
      " 4   Minute      878049 non-null  int16  \n",
      " 5   Hour        878049 non-null  int16  \n",
      " 6   Day         878049 non-null  int16  \n",
      " 7   Month       878049 non-null  int16  \n",
      " 8   Year        878049 non-null  int16  \n",
      " 9   WeekOfYear  878049 non-null  int16  \n",
      " 10  StreetType  878049 non-null  int16  \n",
      " 11  BlockNo     878049 non-null  int16  \n",
      " 12  Rot30_X     878049 non-null  float64\n",
      " 13  Rot30_Y     878049 non-null  float64\n",
      " 14  Rot45_X     878049 non-null  float64\n",
      " 15  Rot45_Y     878049 non-null  float64\n",
      " 16  Rot60_X     878049 non-null  float64\n",
      " 17  Rot60_Y     878049 non-null  float64\n",
      " 18  Radius      878049 non-null  float64\n",
      " 19  Angle       878049 non-null  float64\n",
      " 20  Cluster     878049 non-null  int16  \n",
      "dtypes: float64(10), int16(10), int64(1)\n",
      "memory usage: 90.4 MB\n"
     ]
    }
   ],
   "source": [
    "# # Convert all to 32 bit integers so less memory and will train faster (no loss in data since our integers dont reach)\n",
    "# columns_to_convert = ['DayOfWeek', 'PdDistrict', 'Minute', 'Hour', 'Day', 'Month', 'Year', \n",
    "#                       'Hour_Zone', 'WeekOfYear', 'Season', 'StreetType', 'BlockNo', 'Cluster']\n",
    "columns_to_convert = ['DayOfWeek', 'Minute', 'Hour', 'Day', 'Month', 'Year', \n",
    "                      'WeekOfYear', 'StreetType', 'BlockNo', 'Cluster']\n",
    "train_df[columns_to_convert] = train_df[columns_to_convert].astype('int16')\n",
    "test_df[columns_to_convert] = test_df[columns_to_convert].astype('int16')\n",
    "\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Machine Learning Models\n",
    "\n",
    "- Baseline Models\n",
    "    - Let's train a couple models on a stratified sample of the training data\n",
    "    - Evaluate on a hold out set to get baseline results for each model to determine what model to use\n",
    "    - Models:\n",
    "        - Stochastic Gradient Descent (with elastic net regularization)\n",
    "        - Gaussian Naive Bayes\n",
    "        - K Nearest Neighbors\n",
    "        - Logistic Regression (with L1 regularization)\n",
    "        - Random Forest\n",
    "        - XGBoost\n",
    "    - Almost all the default scikit-learn ML algorithm hyperparameters exhibit bad performance\n",
    "        - Researched online & read literature to determine some more ideal default hyperparameters\n",
    "            - [Reference](https://arxiv.org/abs/1708.05070)\n",
    "- Couple things to note:\n",
    "    - **Decision tree models** including Ensemble methods (Random Forest & XGBoost) can handle categorical variables without one-hot encoding them. \n",
    "    - **Linear models** (SGD & Logistic Regression) cannot handle categorical features & need features to be OHE before training\n",
    "    - Always OneHotEncode before you split data up to training/dev/test so that all features & classes will be represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:36.648460Z",
     "start_time": "2018-09-15T00:15:36.426939Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set training data (drop labels) and training labels\n",
    "X_train = train_df.drop(\"Category\", axis=1).copy()\n",
    "Y_train = train_df[\"Category\"].copy()\n",
    "\n",
    "# Set testing data (drop Id)\n",
    "X_test = test_df.drop(\"Id\", axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:36.668125Z",
     "start_time": "2018-09-15T00:15:36.650857Z"
    }
   },
   "outputs": [],
   "source": [
    "# def one_hot_encode(train_data):\n",
    "#     '''One Hot Encode the categorical features'''\n",
    "#     encoded_train_data = train_data\n",
    "\n",
    "#     encoded_train_data = pd.concat([encoded_train_data, \n",
    "#                                     pd.get_dummies(pd.Series(encoded_train_data['PdDistrict']), prefix='PdDistrict')], axis=1)\n",
    "#     encoded_train_data = pd.concat([encoded_train_data, \n",
    "#                                     pd.get_dummies(pd.Series(encoded_train_data['DayOfWeek']), prefix='DayOfWeek')], axis=1)\n",
    "#     encoded_train_data = pd.concat([encoded_train_data, \n",
    "#                                     pd.get_dummies(pd.Series(encoded_train_data['StreetType']), prefix='StreetType')], axis=1)\n",
    "#     encoded_train_data = pd.concat([encoded_train_data, \n",
    "#                                     pd.get_dummies(pd.Series(encoded_train_data['Season']), prefix='Season')], axis=1)\n",
    "#     encoded_train_data = pd.concat([encoded_train_data, \n",
    "#                                     pd.get_dummies(pd.Series(encoded_train_data['Hour_Zone']), prefix='Hour_Zone')], axis=1)\n",
    "#     encoded_train_data = pd.concat([encoded_train_data, \n",
    "#                                     pd.get_dummies(pd.Series(encoded_train_data['Cluster']), prefix='Cluster')], axis=1)\n",
    "#     encoded_train_data = encoded_train_data.drop(['Cluster','StreetType', 'Season', 'Hour_Zone', 'DayOfWeek', 'PdDistrict'], axis=1)\n",
    "\n",
    "#     return encoded_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:38.078394Z",
     "start_time": "2018-09-15T00:15:36.669880Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_encoded_train = one_hot_encode(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:38.889144Z",
     "start_time": "2018-09-15T00:15:38.080685Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Use these for ML algorithms that can't handle categorical data (Logistic Regression, Linear Models)\n",
    "# mini_encoded_train_data, mini_encoded_dev_data, mini_train_labels, mini_dev_labels = train_test_split(X_encoded_train, \n",
    "#                                                                                       Y_train,\n",
    "#                                                                                       stratify=Y_train,\n",
    "#                                                                                       test_size=0.5,\n",
    "#                                                                                       random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:15:39.373300Z",
     "start_time": "2018-09-15T00:15:38.891328Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use these for ML algorithms that can handle categorical data without OHE\n",
    "mini_train_data, mini_dev_data, mini_train_labels, mini_dev_labels = train_test_split(X_train, \n",
    "                                                                                      Y_train,\n",
    "                                                                                      stratify=Y_train,\n",
    "                                                                                      test_size=0.5,\n",
    "                                                                                      random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:21:04.680834Z",
     "start_time": "2018-09-15T00:15:39.375996Z"
    }
   },
   "outputs": [],
   "source": [
    "# # K Neighbors\n",
    "# knn = KNeighborsClassifier()\n",
    "# knn.fit(mini_train_data, mini_train_labels)\n",
    "# pred_probs = knn.predict_proba(mini_dev_data)\n",
    "# knn_loss = log_loss(mini_dev_labels, pred_probs)\n",
    "\n",
    "\n",
    "# print('KNN Validation Log Loss: ', knn_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:21:10.419938Z",
     "start_time": "2018-09-15T00:21:04.683462Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Naive Bayes\n",
    "# gaussian = GaussianNB()\n",
    "# gaussian.fit(mini_train_data, mini_train_labels)\n",
    "# pred_probs = gaussian.predict_proba(mini_dev_data)\n",
    "# nb_loss = log_loss(mini_dev_labels, pred_probs)\n",
    "\n",
    "\n",
    "# print('Gaussian Naive Bayes Validation Log Loss: ', nb_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T00:22:42.776583Z",
     "start_time": "2018-09-15T00:21:10.422757Z"
    }
   },
   "outputs": [],
   "source": [
    "# # stochastic gradient descent (SGD) learning\n",
    "# sgd = linear_model.SGDClassifier(penalty='elasticnet', loss='log', \n",
    "#                                   tol=0.0001, max_iter=1000, n_jobs=3, random_state=1)\n",
    "# sgd.fit(mini_encoded_train_data, mini_train_labels)\n",
    "# pred_probs = sgd.predict_proba(mini_encoded_dev_data)\n",
    "# # sgd.fit(one_hot_encode(mini_train_data), mini_train_labels)\n",
    "# # sgd = gaussian.predict_proba(one_hot_encode(mini_dev_data))\n",
    "# sgd_loss = log_loss(mini_dev_labels, pred_probs)\n",
    "\n",
    "# print('Linear Model SGD Validation Log Loss: ', sgd_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T04:58:06.514049Z",
     "start_time": "2018-09-15T00:22:42.778440Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Logistic Regression\n",
    "# logreg = LogisticRegression(penalty='l1', C=1.5, solver='saga', multi_class='multinomial', \n",
    "#                             tol=0.0001, max_iter=1000, verbose=3, n_jobs=3, random_state=1)\n",
    "\n",
    "# logreg.fit(mini_encoded_train_data, mini_train_labels)\n",
    "# pred_probs = logreg.predict_proba(mini_encoded_dev_data)\n",
    "\n",
    "# logreg_loss = log_loss(mini_dev_labels, pred_probs)\n",
    "\n",
    "\n",
    "# print('Logistic Regression Validation Log Loss: ', logreg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:04:12.620499Z",
     "start_time": "2018-09-15T04:58:06.515799Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Random Forest Ensemble\n",
    "# random_forest = RandomForestClassifier(n_estimators=500, max_depth=15, max_features='sqrt',\n",
    "#                                        min_samples_leaf=5, min_samples_split=25, \n",
    "#                                        random_state=1, verbose=1, n_jobs=2)\n",
    "\n",
    "\n",
    "# random_forest.fit(mini_train_data, mini_train_labels)\n",
    "# pred_probs = random_forest.predict_proba(mini_dev_data)\n",
    "\n",
    "# rf_loss = log_loss(mini_dev_labels, pred_probs)\n",
    "\n",
    "# print('Random Forest Validation Log Loss: ', rf_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T06:34:32.857467Z",
     "start_time": "2018-09-15T05:04:12.622327Z"
    }
   },
   "outputs": [],
   "source": [
    "# # XGBoost Ensemble \n",
    "# # xgb = XGBClassifier(n_estimators=100, verbose=3, n_jobs=2, random_state=1)\n",
    "# xgb = XGBClassifier(n_estimators=500, objective=\"multi:softprob\", \n",
    "#                     verbose=3, n_jobs=3, random_state=1)\n",
    "\n",
    "# xgb.fit(mini_encoded_train_data, mini_train_labels)\n",
    "# pred_probs = xgb.predict_proba(mini_encoded_dev_data)\n",
    "\n",
    "# xgb_loss = log_loss(mini_dev_labels, pred_probs)\n",
    "\n",
    "# print('XGBoost Validation Log Loss: ', xgb_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T06:34:32.876359Z",
     "start_time": "2018-09-15T06:34:32.859371Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Display the rank of the models\n",
    "# models = pd.DataFrame({\n",
    "#     'Model': ['SGD (Elastic net)', 'Logistic Regression (l1)', 'Random Forest', \n",
    "#               'Gaussian Naive Bayes', 'XGBoost', 'K Neighbors'],\n",
    "#     'Log_Loss': [sgd_loss, logreg_loss, rf_loss, nb_loss, xgb_loss, knn_loss]})\n",
    "# print(models.sort_values(by='Log_Loss', ascending=True).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "- Although Logistic Regression with L1 regularization seems promising, our dataset has a mixture of categorical and numerical features that have very different statistics (mean, variance), thus not very linear. In addition, with any linear model, this would require **one hot encoding** that would greatly increase the feature space (some categorical features such as `BlockNumber` have many levels/values). \n",
    "    - Logistic Regression is a generalized linear model, and can theoretically only solve problems where the classes are linearly separable & features are linear.\n",
    "    - In practice, if we do more feature engineering and convert the non-linear features to linear features, we could increase the performance of LR\n",
    "- Ensemble methods have been historically and theoretically powerful in handling datasets with very different features (numerical & categorical features). In addition, ensemble methods are effective in solving non-linear problems. So, I will select between Random Forest & XGBoost as the final model. \n",
    "    - The caveat is that the default hyperparameters for RF & XGB are generally not optimal for the problem in hand, so hyperparameter tuning is necessary, which can take a while since there are so many hyperparameters to tune for (at least in XGB)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "- Hyperparameter tuning involves defining an objective function (log loss), and using cross-validation to measure the hyperparameter quality. \n",
    "    - We want the hyperparameters that give the highest generalization performance.\n",
    "- Three approaches: Grid Search (`GridSearchCV`), Random Search (`RandomSearchCV`), and Bayes Optimization (`BayesSearchCV`)\n",
    "- Realized `GridSearchCV` took way too long and was impractical, and `RandomSearchCV` was too random.\n",
    "    - Grid and random search are completely uninformed by past evaluations, and as a result, often spend a significant amount of time evaluating â€œbadâ€ hyperparameters.\n",
    "- Then, I did more research on more efficient & smarter hyperparameter tuning techniques and found Bayeisan Optimization (`BayesSearchCV`)\n",
    "- **Bayesian Optimization Overview**\n",
    "    - Build a probabilistic model of the objective function & use it to select promising hyperparameters to evaluate in the true objective function\n",
    "        - The model used for approximating the objective function is called *surrogate model*. \n",
    "            - E.g. Gaussian Processes \n",
    "    - Keeps track of past evaluation results, which is used to form a probabilistic model mapping hyperparameters to a probability of a score on the objective function\n",
    "    - Instead of optimizing an expensive objective function, we optimize on a cheap proxy function instead.\n",
    "        - *Acquisition function* that directs sampling to areas where an improvement over the current best observation is likely.\n",
    "            - E.g. maximum probability of improvement (MPI), expected improvement (EI) and upper confidence bound (UCB)\n",
    "- **K-Folds Cross Validation**\n",
    "    - Use cross validation to measure the true generalization performance of a model \n",
    "    - This is integrated with the hyperparameter tuning techniques (`GridSearchCV`, `RandomSearchCV`, `BayesSearchCV`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "## Random Forest (Bagging)\n",
    "\n",
    "- Basic Overview\n",
    "    - An ensemble method that utilizes Bagging (Bootstrapp Aggregation or sampling with replacement)\n",
    "    - Bagging helps reduce **variance** in any single learner (Decision Trees)\n",
    "- Basic Steps:\n",
    "    1. Several decision trees which are generated in parallel, form the base learners of bagging technique.\n",
    "    2. Data sampled with replacement is fed to these learners for training.\n",
    "    3. The final prediction is the averaged output from all the learners.\n",
    "   \n",
    "\n",
    "**Things I learned**:\n",
    "- Since the random forest model is overfitting, we want to increase the **min** parameters of random forest and decrease the **max** parameters of random forest\n",
    "- increasing n_estimators will prevent the random forest from **overfitting**\n",
    "    - lower number of n_estimators will be similiar to just a simple decision tree (very prone to overfitting)\n",
    "- increasing max depth will increase **variance** (overfitting, sensitivity to training set) and decrease **bias**\n",
    "- increasing min samples leaf will decrease **variance** and increase **bias**.\n",
    "- decreasing any of the **max*** parameters and increasing any of the **min*** parameters will increase **regularization**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T06:34:33.878874Z",
     "start_time": "2018-09-15T06:34:33.825618Z"
    }
   },
   "outputs": [],
   "source": [
    "# n_features = X_train.shape[1]\n",
    "\n",
    "\n",
    "# opt = BayesSearchCV(\n",
    "#     estimator=RandomForestClassifier(oob_score=True, random_state=1, n_jobs=2),\n",
    "#     search_spaces= \n",
    "#     {\n",
    "#         'n_estimators': (100, 600),\n",
    "#         'max_depth': (1, 50),  \n",
    "#         'max_features': (1, n_features),\n",
    "#         'min_samples_leaf': (1, 50),  # integer valued parameter\n",
    "#         'min_samples_split': (2, 50),\n",
    "#     },\n",
    "#     n_iter=20,\n",
    "#     optimizer_kwargs= {'base_estimator': 'RF'},\n",
    "#     scoring='neg_log_loss',\n",
    "#     n_jobs=5,\n",
    "#     verbose=0,\n",
    "#     cv = StratifiedKFold(\n",
    "#         n_splits=3,\n",
    "#         shuffle=True,\n",
    "#         random_state=1\n",
    "#     ),\n",
    "#     random_state=1\n",
    "    \n",
    "# )\n",
    "\n",
    "\n",
    "# def status_print(optim_result):\n",
    "#     \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
    "    \n",
    "#     # Get all the models tested so far in DataFrame format\n",
    "#     all_models = pd.DataFrame(opt.cv_results_)    \n",
    "    \n",
    "#     # Get current parameters and the best parameters    \n",
    "#     best_params = pd.Series(opt.best_params_)\n",
    "#     print('Model #{}\\nBest LogLoss: {}\\nBest params: {}\\n'.format(\n",
    "#         len(all_models),\n",
    "#         np.round(opt.best_score_, 6),\n",
    "#         opt.best_params_\n",
    "#     ))\n",
    "    \n",
    "#     # Save all model results\n",
    "#     clf_name = opt.estimator.__class__.__name__\n",
    "#     all_models.to_csv(clf_name + \"_cv_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T11:29:52.084160Z",
     "start_time": "2018-09-15T06:34:33.881264Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# result = opt.fit(X_train.values, Y_train.values, callback=status_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T04:55:53.896268Z",
     "start_time": "2018-09-17T04:55:53.757495Z"
    }
   },
   "outputs": [],
   "source": [
    "# result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost (Boosting)\n",
    "\n",
    "- Basic Overview:\n",
    "    - Another ensemble method that uses Boosting instead of Bagging (Random Forests)\n",
    "    - In **Boosting**, the trees are built sequentially such that each subsequent tree aims to reduce the errors of the previous tree.\n",
    "    - Each tree learns from its predecessors and updates the residual errors. \n",
    "    - Each base learner is weak (high bias) and contributes some vital information for prediction, enabling the boosting technique to produce a strong learner by effectively combining these weak learners.\n",
    "    - The final strong learner brings down both the **bias** and the **variance**.\n",
    "    - In contrast to bagging techniques like Random Forest, in which trees are grown to their maximum extent, boosting makes use of trees with fewer splits\n",
    "        -  Such small trees, which are not very deep, are **highly interpretable**. \n",
    "- Basic Steps:\n",
    "    1. Initial model `F0` to predict target variable `y`. Used to also calculate residual (`y - F0`)\n",
    "    2. A new model `h1` is used to fit to the residuals from the previous step\n",
    "    3. Now, `F0` and `h1` are combined to give `F1`, which is the boosted version of `F0`. \n",
    "        - The MSE or whatever cost function you use (Log loss, MAE) of `F1` will be lower than `F0`.\n",
    "    4. Iterate the above steps to create new models based off the previous models.\n",
    "    \n",
    "### Prevent Overfitting:\n",
    "- Large number of trees will cause overfitting (unlike Random Forests)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T21:03:55.844774Z",
     "start_time": "2018-09-15T21:03:55.779287Z"
    }
   },
   "outputs": [],
   "source": [
    "# # log-uniform: understand as search over p = exp(x) by varying x\n",
    "# bayes_cv_tuner = BayesSearchCV(\n",
    "#     estimator = XGBClassifier(\n",
    "#         n_jobs = 3,\n",
    "#         objective = 'multi:softprob',\n",
    "#         eval_metric = 'mlogloss',\n",
    "#         verbosity=1,\n",
    "#         random_state=1\n",
    "#     ),\n",
    "#     search_spaces = {\n",
    "#         'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "#         'min_child_weight': (0, 10),\n",
    "#         'max_depth': (1, 100),\n",
    "#         'max_delta_step': (0, 20),\n",
    "#         'subsample': (0.01, 1.0, 'uniform'),\n",
    "#         'colsample_bytree': (0.01, 1.0, 'uniform'),\n",
    "#         'colsample_bylevel': (0.01, 1.0, 'uniform'),\n",
    "#         'reg_lambda': (1e-9, 1000, 'log-uniform'),\n",
    "#         'reg_alpha': (1e-9, 1.0, 'log-uniform'),\n",
    "#         'gamma': (1e-9, 0.5, 'log-uniform'),\n",
    "#         'min_child_weight': (0, 5),\n",
    "#         'n_estimators': (50, 300),\n",
    "#         'scale_pos_weight': (1e-6, 500, 'log-uniform')\n",
    "#     },    \n",
    "#     scoring = 'neg_log_loss',\n",
    "#     cv = StratifiedKFold(\n",
    "#         n_splits=3,\n",
    "#         shuffle=True,\n",
    "#         random_state=1\n",
    "#     ),\n",
    "#     n_jobs = 6,\n",
    "#     n_iter = 20,   \n",
    "#     verbose = 0,\n",
    "#     refit = True,\n",
    "#     random_state = 1\n",
    "# )\n",
    "\n",
    "# def status_print(optim_result):\n",
    "#     \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
    "    \n",
    "#     # Get all the models tested so far in DataFrame format\n",
    "#     all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n",
    "    \n",
    "#     # Get current parameters and the best parameters    \n",
    "#     best_params = pd.Series(bayes_cv_tuner.best_params_)\n",
    "#     print('Model #{}\\nBest Log Loss: {}\\nBest params: {}\\n'.format(\n",
    "#         len(all_models),\n",
    "#         np.round(bayes_cv_tuner.best_score_, 8),\n",
    "#         bayes_cv_tuner.best_params_\n",
    "#     ))\n",
    "    \n",
    "#     # Save all model results\n",
    "#     clf_name = bayes_cv_tuner.estimator.__class__.__name__\n",
    "#     all_models.to_csv(clf_name + \"_cv_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit the model\n",
    "# result = bayes_cv_tuner.fit(X_train.values, Y_train.values, callback=status_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print best params\n",
    "# result.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "XGBoost Best params:\n",
    "\n",
    "{'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'gamma': 0.49999999999999994, 'learning_rate': 0.1858621466840661, \n",
    "'max_delta_step': 0, 'max_depth': 50, 'min_child_weight': 5, 'n_estimators': 86, 'reg_alpha': 1.0, 'reg_lambda': 60.121460571845695, 'scale_pos_weight': 1e-06, 'subsample': 1.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model with optimal hyperparameters & all features\n",
    "\n",
    "- Initially, I started with a Random Forest, but decided to use XGBoost\n",
    "- We first train the model (with all the features) using the optimal hyperparameters that were found through `BayesSearchCV`\n",
    "- Then, I use the model to predict the probabilities of test set with all the features\n",
    "    - I'll save these predictions later to compare them with another model I will train with certain features removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T08:00:30.846347Z",
     "start_time": "2018-09-17T05:06:43.255143Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/me/.conda/envs/py39/lib/python3.9/site-packages/xgboost/data.py:173: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# It seems running time scales quadratically with the number of classes\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=86, \n",
    "    objective=\"multi:softprob\", \n",
    "    learning_rate=0.1858621466840661,\n",
    "    colsample_bylevel=1.0,\n",
    "    colsample_bytree=1.0,\n",
    "    gamma=0.49999999999999994,\n",
    "    max_delta_step=0,\n",
    "    max_depth=50,\n",
    "    min_child_weight=5,\n",
    "    reg_alpha=1.0,\n",
    "    reg_lambda=60.121460571845695,\n",
    "    scale_pos_weight=1e-06,\n",
    "    subsample=1.0,\n",
    "    random_state=1, \n",
    "    n_jobs=4,\n",
    "    verbosity=0)\n",
    "\n",
    "\n",
    "xgb.fit(X_train, Y_train)\n",
    "\n",
    "Y_test_pred = xgb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-08T08:58:59.498448Z",
     "start_time": "2018-09-08T08:27:44.681456Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# random_forest = RandomForestClassifier(n_estimators=600, max_depth=21, max_features=6,\n",
    "#                                        min_samples_leaf=43, min_samples_split=40, \n",
    "#                                        random_state=1, verbose=3, n_jobs=2)\n",
    "# random_forest.fit(X_train, Y_train)\n",
    "\n",
    "# Y_test_pred = random_forest.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance\n",
    "\n",
    "- Measured by mean decrease in Gini information\n",
    "- This is a form of feature selection that ensemble methods (Random Forest, XGBoost) can use to prevent overfitting\n",
    "    - I drop the features that seem unimportant & with less than a 1% contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T08:00:40.093635Z",
     "start_time": "2018-09-17T08:00:30.849884Z"
    }
   },
   "outputs": [],
   "source": [
    "importances = pd.DataFrame({'feature': X_train.columns,\n",
    "                            'importance': np.round(xgb.feature_importances_, 5)})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T08:00:40.175114Z",
     "start_time": "2018-09-17T08:00:40.097249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Minute</th>\n",
       "      <td>0.12823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlockNo</th>\n",
       "      <td>0.09031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rot30_Y</th>\n",
       "      <td>0.06055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rot45_Y</th>\n",
       "      <td>0.05901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radius</th>\n",
       "      <td>0.05781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster</th>\n",
       "      <td>0.05382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rot60_X</th>\n",
       "      <td>0.05061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hour</th>\n",
       "      <td>0.04958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rot60_Y</th>\n",
       "      <td>0.04606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rot30_X</th>\n",
       "      <td>0.04587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>0.04520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.04424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0.04409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rot45_X</th>\n",
       "      <td>0.04224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angle</th>\n",
       "      <td>0.04077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StreetType</th>\n",
       "      <td>0.03321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DayOfWeek</th>\n",
       "      <td>0.02848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WeekOfYear</th>\n",
       "      <td>0.02748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>0.02622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day</th>\n",
       "      <td>0.02622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            importance\n",
       "feature               \n",
       "Minute         0.12823\n",
       "BlockNo        0.09031\n",
       "Rot30_Y        0.06055\n",
       "Rot45_Y        0.05901\n",
       "Radius         0.05781\n",
       "Cluster        0.05382\n",
       "Rot60_X        0.05061\n",
       "Hour           0.04958\n",
       "Rot60_Y        0.04606\n",
       "Rot30_X        0.04587\n",
       "Year           0.04520\n",
       "X              0.04424\n",
       "Y              0.04409\n",
       "Rot45_X        0.04224\n",
       "Angle          0.04077\n",
       "StreetType     0.03321\n",
       "DayOfWeek      0.02848\n",
       "WeekOfYear     0.02748\n",
       "Month          0.02622\n",
       "Day            0.02622"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Removal\n",
    "\n",
    "- Remove features to simplify model and prevent overfitting\n",
    "- Drop anything that contributes under 1% to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T08:14:35.010195Z",
     "start_time": "2018-09-17T08:14:34.817218Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train = X_train.drop(\"BusinessHour\", axis=1)\n",
    "# X_test  = X_test.drop(\"BusinessHour\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T08:14:36.108016Z",
     "start_time": "2018-09-17T08:14:35.943995Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train = X_train.drop(\"PdDistrict\", axis=1)\n",
    "# X_test  = X_test.drop(\"PdDistrict\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T08:14:36.487347Z",
     "start_time": "2018-09-17T08:14:36.397874Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train = X_train.drop(\"Holiday\", axis=1)\n",
    "# X_test  = X_test.drop(\"Holiday\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T08:14:53.358791Z",
     "start_time": "2018-09-17T08:14:53.260800Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train = X_train.drop(\"Weekend\", axis=1)\n",
    "# X_test  = X_test.drop(\"Weekend\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T08:14:53.946694Z",
     "start_time": "2018-09-17T08:14:53.897524Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T08:14:54.532223Z",
     "start_time": "2018-09-17T08:14:54.508723Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train final model with optimal hyperparameters & features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T10:48:47.621060Z",
     "start_time": "2018-09-17T08:18:41.414908Z"
    }
   },
   "outputs": [],
   "source": [
    "# # It seems running time scales quadratically with the number of classes\n",
    "# xgb = XGBClassifier(\n",
    "#     n_estimators=86, \n",
    "#     objective=\"multi:softprob\", \n",
    "#     learning_rate=0.1858621466840661,\n",
    "#     colsample_bylevel=1.0,\n",
    "#     colsample_bytree=1.0,\n",
    "#     gamma=0.49999999999999994,\n",
    "#     max_delta_step=0,\n",
    "#     max_depth=50,\n",
    "#     min_child_weight=5,\n",
    "#     reg_alpha=1.0,\n",
    "#     reg_lambda=60.121460571845695,\n",
    "#     scale_pos_weight=1e-06,\n",
    "#     subsample=1.0,\n",
    "#     random_state=1, \n",
    "#     n_jobs=4,\n",
    "#     verbosity=0)\n",
    "\n",
    "\n",
    "# xgb.fit(X_train, Y_train)\n",
    "\n",
    "# Y_test_pred = xgb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Random Forest Model\n",
    "\n",
    "# random_forest = RandomForestClassifier(n_estimators=600, max_depth=21, max_features=6,\n",
    "#                                        min_samples_leaf=43, min_samples_split=40, \n",
    "#                                        random_state=1, verbose=3, n_jobs=2)\n",
    "# random_forest.fit(X_train, Y_train)\n",
    "\n",
    "# Y_test_pred = random_forest.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "- Evaluate final model based on K-Fold cross validation\n",
    "- Average all K iterations to give the true estimate of the final model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T04:41:05.199240Z",
     "start_time": "2018-09-02T04:27:11.535Z"
    }
   },
   "outputs": [],
   "source": [
    "# scores = cross_val_score(xgb, X_train, Y_train, \n",
    "#                          cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=1), \n",
    "#                          scoring = \"neg_log_loss\", n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T04:41:05.202180Z",
     "start_time": "2018-09-02T04:27:11.537Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(\"Scores:\", scores)\n",
    "# print(\"Mean:\", scores.mean())\n",
    "# print(\"Standard Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Submission\n",
    "\n",
    "- Reformat and turn in predictions and results from our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T10:48:47.627937Z",
     "start_time": "2018-09-17T10:48:47.623352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(884262, 39)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T11:06:50.148631Z",
     "start_time": "2018-09-17T11:06:47.249150Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T11:06:50.154768Z",
     "start_time": "2018-09-17T11:06:50.150430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(884262, 40)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T11:06:54.120643Z",
     "start_time": "2018-09-17T11:06:50.157476Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_submission.iloc[:, 1:] = pd.DataFrame(Y_test_pred, columns=sample_submission.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T11:06:54.159292Z",
     "start_time": "2018-09-17T11:06:54.122433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ARSON</th>\n",
       "      <th>ASSAULT</th>\n",
       "      <th>BAD CHECKS</th>\n",
       "      <th>BRIBERY</th>\n",
       "      <th>BURGLARY</th>\n",
       "      <th>DISORDERLY CONDUCT</th>\n",
       "      <th>DRIVING UNDER THE INFLUENCE</th>\n",
       "      <th>DRUG/NARCOTIC</th>\n",
       "      <th>DRUNKENNESS</th>\n",
       "      <th>...</th>\n",
       "      <th>SEX OFFENSES NON FORCIBLE</th>\n",
       "      <th>STOLEN PROPERTY</th>\n",
       "      <th>SUICIDE</th>\n",
       "      <th>SUSPICIOUS OCC</th>\n",
       "      <th>TREA</th>\n",
       "      <th>TRESPASS</th>\n",
       "      <th>VANDALISM</th>\n",
       "      <th>VEHICLE THEFT</th>\n",
       "      <th>WARRANTS</th>\n",
       "      <th>WEAPON LAWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004332</td>\n",
       "      <td>0.084118</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.031691</td>\n",
       "      <td>0.002241</td>\n",
       "      <td>0.012754</td>\n",
       "      <td>0.035729</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.005054</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.075366</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.007972</td>\n",
       "      <td>0.028111</td>\n",
       "      <td>0.254697</td>\n",
       "      <td>0.027866</td>\n",
       "      <td>0.032650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.023080</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.011173</td>\n",
       "      <td>0.039749</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.048660</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.011080</td>\n",
       "      <td>0.016582</td>\n",
       "      <td>0.135156</td>\n",
       "      <td>0.016404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.166355</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.056119</td>\n",
       "      <td>0.002595</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>0.032885</td>\n",
       "      <td>0.008286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.078208</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.013205</td>\n",
       "      <td>0.048056</td>\n",
       "      <td>0.030266</td>\n",
       "      <td>0.029374</td>\n",
       "      <td>0.009819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.199844</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.036891</td>\n",
       "      <td>0.004805</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.037625</td>\n",
       "      <td>0.020117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.010019</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.064655</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>0.050839</td>\n",
       "      <td>0.087281</td>\n",
       "      <td>0.032818</td>\n",
       "      <td>0.024386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.199844</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.036891</td>\n",
       "      <td>0.004805</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.037625</td>\n",
       "      <td>0.020117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.010019</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.064655</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>0.050839</td>\n",
       "      <td>0.087281</td>\n",
       "      <td>0.032818</td>\n",
       "      <td>0.024386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.066103</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.011566</td>\n",
       "      <td>0.009420</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.012217</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.026069</td>\n",
       "      <td>0.034061</td>\n",
       "      <td>0.039782</td>\n",
       "      <td>0.015867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>0.027117</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.120133</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.005125</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.011556</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.065712</td>\n",
       "      <td>0.371637</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>0.003320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>0.046458</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.086475</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.004460</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.017591</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>0.046025</td>\n",
       "      <td>0.366005</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>0.003355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.001983</td>\n",
       "      <td>0.193583</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.034731</td>\n",
       "      <td>0.006166</td>\n",
       "      <td>0.005540</td>\n",
       "      <td>0.066320</td>\n",
       "      <td>0.009537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.008940</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.051507</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.049745</td>\n",
       "      <td>0.006842</td>\n",
       "      <td>0.082704</td>\n",
       "      <td>0.022529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.070476</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.015563</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.005509</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.017559</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.036083</td>\n",
       "      <td>0.016194</td>\n",
       "      <td>0.030135</td>\n",
       "      <td>0.005755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id     ARSON   ASSAULT  BAD CHECKS   BRIBERY  BURGLARY  DISORDERLY CONDUCT  \\\n",
       "0   0  0.004332  0.084118    0.000184  0.000967  0.031691            0.002241   \n",
       "1   1  0.001050  0.023080    0.000082  0.000532  0.001155            0.001989   \n",
       "2   2  0.003186  0.166355    0.000224  0.000394  0.056119            0.002595   \n",
       "3   3  0.002166  0.199844    0.000294  0.002285  0.036891            0.004805   \n",
       "4   4  0.002166  0.199844    0.000294  0.002285  0.036891            0.004805   \n",
       "5   5  0.001262  0.066103    0.000079  0.000396  0.000805            0.001046   \n",
       "6   6  0.001622  0.027117    0.000073  0.000573  0.120133            0.001048   \n",
       "7   7  0.002454  0.046458    0.000073  0.000693  0.086475            0.000869   \n",
       "8   8  0.001983  0.193583    0.000154  0.001945  0.034731            0.006166   \n",
       "9   9  0.000963  0.070476    0.000083  0.000142  0.003767            0.001107   \n",
       "\n",
       "   DRIVING UNDER THE INFLUENCE  DRUG/NARCOTIC  DRUNKENNESS  ...  \\\n",
       "0                     0.012754       0.035729     0.003803  ...   \n",
       "1                     0.011173       0.039749     0.002212  ...   \n",
       "2                     0.002184       0.032885     0.008286  ...   \n",
       "3                     0.003935       0.037625     0.020117  ...   \n",
       "4                     0.003935       0.037625     0.020117  ...   \n",
       "5                     0.011566       0.009420     0.003665  ...   \n",
       "6                     0.001721       0.005125     0.001125  ...   \n",
       "7                     0.001098       0.004866     0.001980  ...   \n",
       "8                     0.005540       0.066320     0.009537  ...   \n",
       "9                     0.003641       0.015563     0.005306  ...   \n",
       "\n",
       "   SEX OFFENSES NON FORCIBLE  STOLEN PROPERTY   SUICIDE  SUSPICIOUS OCC  \\\n",
       "0                   0.000186         0.005054  0.000741        0.075366   \n",
       "1                   0.000106         0.003493  0.000099        0.048660   \n",
       "2                   0.000115         0.007979  0.000801        0.078208   \n",
       "3                   0.000263         0.010019  0.000748        0.064655   \n",
       "4                   0.000263         0.010019  0.000748        0.064655   \n",
       "5                   0.000146         0.004226  0.000127        0.012217   \n",
       "6                   0.000090         0.002451  0.000362        0.011556   \n",
       "7                   0.000109         0.004460  0.000289        0.017591   \n",
       "8                   0.000146         0.008940  0.000413        0.051507   \n",
       "9                   0.000071         0.005509  0.000134        0.017559   \n",
       "\n",
       "       TREA  TRESPASS  VANDALISM  VEHICLE THEFT  WARRANTS  WEAPON LAWS  \n",
       "0  0.000042  0.007972   0.028111       0.254697  0.027866     0.032650  \n",
       "1  0.000030  0.000595   0.011080       0.016582  0.135156     0.016404  \n",
       "2  0.000038  0.013205   0.048056       0.030266  0.029374     0.009819  \n",
       "3  0.000049  0.004594   0.050839       0.087281  0.032818     0.024386  \n",
       "4  0.000049  0.004594   0.050839       0.087281  0.032818     0.024386  \n",
       "5  0.000028  0.000564   0.026069       0.034061  0.039782     0.015867  \n",
       "6  0.000022  0.002015   0.065712       0.371637  0.004020     0.003320  \n",
       "7  0.000023  0.004120   0.046025       0.366005  0.003065     0.003355  \n",
       "8  0.000039  0.009237   0.049745       0.006842  0.082704     0.022529  \n",
       "9  0.000028  0.000529   0.036083       0.016194  0.030135     0.005755  \n",
       "\n",
       "[10 rows x 40 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T11:07:37.190126Z",
     "start_time": "2018-09-17T11:06:54.161512Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv('data/submission_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "- After lots of tuning, I finally achieved a kaggle evaluation score (multiclass log loss) of **2.25674**, which would ideally rank at **#136** (out of 2,335 teams) or at the **top 6%** or **94th percentile** on the public leaderboard\n",
    "    - Since this is an old kaggle competition, this would most likely be a lower rank, but I still felt proud to achieve this score\n",
    "    - It is possible that I could run more experiments and tune the hyperparameters to achieve an even better score & ranking \n",
    "    - This was more of a learning experience for me & to get my feet wet with Data Science projects & Kaggle competitions\n",
    "    - In an effort to learn, I refrained from looking up old Kaggle kernels & other resources that completed this specific Kaggle competition.\n",
    "    - I coded most of this myself to learn the data science libraries, but did use resources such as other Kaggle competition kernels and research papers to get a better idea of how to think about the data. Google is awesome.\n",
    "- Below, I show images of my two highest scoring submissions on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T11:45:15.757302Z",
     "start_time": "2018-09-17T11:45:15.694747Z"
    }
   },
   "outputs": [],
   "source": [
    "# from IPython.display import Image\n",
    "# Image(filename='images/best_kaggle_submission.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T11:45:26.073609Z",
     "start_time": "2018-09-17T11:45:26.066850Z"
    }
   },
   "outputs": [],
   "source": [
    "# Image(filename='images/2nd_best_kaggle_submission.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This project has taught me a lot about data science and has given me hands-on experience with working with data and completing an end-to-end data science project. I've had a lot of fun visualizing, analyzing, and experimenting with the data to gain more insight. This is just the beginning of my journey into data science, and I am very excited to see what the future holds in terms of new and interesting data science problems and datasets.\n",
    "\n",
    "- **What I learned**:\n",
    "    - There are more efficient ways to label or integer encode features\n",
    "        - Will use sklearn's LabelEncoder, OneHotEncoder, & MultiLabelBinarizer next time\n",
    "    - Instead of just blindly training models, research more about ways to optimize the hyperparameters efficiently\n",
    "        - Spent too many AWS EC2 hours with `GridSearchCV`, when I should have used *Bayesian Optimization* for efficient hyperparameter tuning\n",
    "        - Do more research on the domain of the problem, certain core ML algorithms, and data processing techniques\n",
    "- **What's next?**\n",
    "    - AutoML with `tpot` or `auto-sklearn`\n",
    "        - automate the hyperparameter tuning and model selection with AutoML packages\n",
    "    - Problem Redirection (Classification ---> Regression)\n",
    "        - Instead of predicting category of crime, predict X & Y coordinates (longitude & latitude) continuous values given same spatial and temporal features as well as category of crime\n",
    "        - **Use case:** Dynamically concentrate police on certain serious categories of crime to prevent crimes from happening beforehand\n",
    "    - Rewrite all code in the jupyter notebook to .py files\n",
    "        - Modularize each of the steps with functions and/or classes\n",
    "        - Useful because I can run the .py file on AWS EC2 without having to host it on jupyter notebook locally\n",
    "            - Meaning I can peacefully shut down my laptop and let script run in the cloud overnight\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c826e536c3a505596f0e2d06b1e710c70fa81f3ad055524c17f65f2bf85a16c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
